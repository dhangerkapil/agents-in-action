{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat Middleware\n",
    "\n",
    "This notebook demonstrates chat middleware for intercepting and modifying chat messages.\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "- **Message Observation**: Observe and log input messages\n",
    "- **Message Modification**: Modify messages before sending to AI\n",
    "- **Response Override**: Override entire AI responses\n",
    "- **Agent-level vs Run-level**: Apply middleware globally or per-run\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Azure AI Foundry project endpoint configured in `.env`\n",
    "- `agent-framework` package installed\n",
    "- Azure CLI authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../.env')\n",
    "\n",
    "project_endpoint = os.getenv(\"AZURE_AI_PROJECT_ENDPOINT\")\n",
    "model_deployment_name = os.getenv(\"AZURE_AI_MODEL_DEPLOYMENT_NAME\")\n",
    "\n",
    "print(f\"Project Endpoint: {project_endpoint}\")\n",
    "print(f\"Model Deployment: {model_deployment_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Awaitable, Callable\n",
    "from random import randint\n",
    "from typing import Annotated\n",
    "\n",
    "from agent_framework import (\n",
    "    ChatContext,\n",
    "    ChatMessage,\n",
    "    ChatMiddleware,\n",
    "    ChatResponse,\n",
    "    Role,\n",
    "    chat_middleware,\n",
    ")\n",
    "from agent_framework.azure import AzureAIAgentClient\n",
    "from azure.identity.aio import AzureCliCredential\n",
    "from pydantic import Field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Tool Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(\n",
    "    location: Annotated[str, Field(description=\"The location to get the weather for.\")],\n",
    ") -> str:\n",
    "    \"\"\"Get the weather for a given location.\"\"\"\n",
    "    conditions = [\"sunny\", \"cloudy\", \"rainy\", \"stormy\"]\n",
    "    return f\"The weather in {location} is {conditions[randint(0, 3)]} with a high of {randint(10, 30)}\u00b0C.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Middleware Classes\n",
    "\n",
    "This sample demonstrates how to use chat middleware to observe and override\n",
    "inputs sent to AI models. Chat middleware intercepts chat requests before they reach\n",
    "the underlying AI service, allowing you to:\n",
    "\n",
    "1. Observe and log input messages\n",
    "2. Modify input messages before sending to AI\n",
    "3. Override the entire response\n",
    "\n",
    "The example covers:\n",
    "- Class-based chat middleware inheriting from ChatMiddleware\n",
    "- Function-based chat middleware with @chat_middleware decorator\n",
    "- Middleware registration at agent level (applies to all runs)\n",
    "- Middleware registration at run level (applies to specific run only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputObserverMiddleware(ChatMiddleware):\n",
    "    \"\"\"Class-based middleware that observes and modifies input messages.\"\"\"\n",
    "\n",
    "    def __init__(self, replacement: str | None = None):\n",
    "        \"\"\"Initialize with a replacement for user messages.\"\"\"\n",
    "        self.replacement = replacement\n",
    "\n",
    "    async def process(\n",
    "        self,\n",
    "        context: ChatContext,\n",
    "        next: Callable[[ChatContext], Awaitable[None]],\n",
    "    ) -> None:\n",
    "        \"\"\"Observe and modify input messages before they are sent to AI.\"\"\"\n",
    "        print(\"[InputObserverMiddleware] Observing input messages:\")\n",
    "\n",
    "        for i, message in enumerate(context.messages):\n",
    "            content = message.text if message.text else str(message.contents)\n",
    "            print(f\"  Message {i + 1} ({message.role.value}): {content}\")\n",
    "\n",
    "        print(f\"[InputObserverMiddleware] Total messages: {len(context.messages)}\")\n",
    "\n",
    "        # Modify user messages by creating new messages with enhanced text\n",
    "        modified_messages: list[ChatMessage] = []\n",
    "        modified_count = 0\n",
    "\n",
    "        for message in context.messages:\n",
    "            if message.role == Role.USER and message.text:\n",
    "                original_text = message.text\n",
    "                updated_text = original_text\n",
    "\n",
    "                if self.replacement:\n",
    "                    updated_text = self.replacement\n",
    "                    print(f\"[InputObserverMiddleware] Updated: '{original_text}' -> '{updated_text}'\")\n",
    "\n",
    "                modified_message = ChatMessage(role=message.role, text=updated_text)\n",
    "                modified_messages.append(modified_message)\n",
    "                modified_count += 1\n",
    "            else:\n",
    "                modified_messages.append(message)\n",
    "\n",
    "        # Replace messages in context\n",
    "        context.messages[:] = modified_messages\n",
    "\n",
    "        # Continue to next middleware or AI execution\n",
    "        await next(context)\n",
    "\n",
    "        # Observe that processing is complete\n",
    "        print(\"[InputObserverMiddleware] Processing completed\")\n",
    "\n",
    "\n",
    "@chat_middleware\n",
    "async def security_and_override_middleware(\n",
    "    context: ChatContext,\n",
    "    next: Callable[[ChatContext], Awaitable[None]],\n",
    ") -> None:\n",
    "    \"\"\"Function-based middleware that implements security filtering and response override.\"\"\"\n",
    "    print(\"[SecurityMiddleware] Processing input...\")\n",
    "\n",
    "    # Security check - block sensitive information\n",
    "    blocked_terms = [\"password\", \"secret\", \"api_key\", \"token\"]\n",
    "\n",
    "    for message in context.messages:\n",
    "        if message.text:\n",
    "            message_lower = message.text.lower()\n",
    "            for term in blocked_terms:\n",
    "                if term in message_lower:\n",
    "                    print(f\"[SecurityMiddleware] BLOCKED: Found '{term}' in message\")\n",
    "\n",
    "                    # Override the response instead of calling AI\n",
    "                    context.result = ChatResponse(\n",
    "                        messages=[\n",
    "                            ChatMessage(\n",
    "                                role=Role.ASSISTANT,\n",
    "                                text=\"I cannot process requests containing sensitive information. \"\n",
    "                                \"Please rephrase your question without including passwords, secrets, or other \"\n",
    "                                \"sensitive data.\",\n",
    "                            )\n",
    "                        ]\n",
    "                    )\n",
    "\n",
    "                    # Set terminate flag to stop execution\n",
    "                    context.terminate = True\n",
    "                    return\n",
    "\n",
    "    # Continue to next middleware or AI execution\n",
    "    await next(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Class-based Chat Middleware (Agent Level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def class_based_chat_middleware():\n",
    "    \"\"\"Demonstrate class-based middleware at agent level.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Class-based Chat Middleware (Agent Level)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    async with (\n",
    "        AzureCliCredential() as credential,\n",
    "        AzureAIAgentClient(async_credential=credential).create_agent(\n",
    "            name=\"EnhancedChatAgent\",\n",
    "            instructions=\"You are a helpful AI assistant.\",\n",
    "            # Register class-based middleware at agent level (applies to all runs)\n",
    "            middleware=InputObserverMiddleware(),\n",
    "            tools=get_weather,\n",
    "        ) as agent,\n",
    "    ):\n",
    "        query = \"What's the weather in Seattle?\"\n",
    "        print(f\"User: {query}\")\n",
    "        result = await agent.run(query)\n",
    "        print(f\"Final Response: {result.text if result.text else 'No response'}\")\n",
    "\n",
    "await class_based_chat_middleware()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Function-based Chat Middleware (Agent Level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def function_based_chat_middleware():\n",
    "    \"\"\"Demonstrate function-based middleware at agent level.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Function-based Chat Middleware (Agent Level)\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    async with (\n",
    "        AzureCliCredential() as credential,\n",
    "        AzureAIAgentClient(async_credential=credential).create_agent(\n",
    "            name=\"FunctionMiddlewareAgent\",\n",
    "            instructions=\"You are a helpful AI assistant.\",\n",
    "            # Register function-based middleware at agent level\n",
    "            middleware=security_and_override_middleware,\n",
    "        ) as agent,\n",
    "    ):\n",
    "        # Scenario with normal query\n",
    "        print(\"\\n--- Scenario 1: Normal Query ---\")\n",
    "        query = \"Hello, how are you?\"\n",
    "        print(f\"User: {query}\")\n",
    "        result = await agent.run(query)\n",
    "        print(f\"Final Response: {result.text if result.text else 'No response'}\")\n",
    "\n",
    "        # Scenario with security violation\n",
    "        print(\"\\n--- Scenario 2: Security Violation ---\")\n",
    "        query = \"What is my password for this account?\"\n",
    "        print(f\"User: {query}\")\n",
    "        result = await agent.run(query)\n",
    "        print(f\"Final Response: {result.text if result.text else 'No response'}\")\n",
    "\n",
    "await function_based_chat_middleware()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Run-level Middleware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_level_middleware():\n",
    "    \"\"\"Demonstrate middleware registration at run level.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Run-level Chat Middleware\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    async with (\n",
    "        AzureCliCredential() as credential,\n",
    "        AzureAIAgentClient(async_credential=credential).create_agent(\n",
    "            name=\"RunLevelAgent\",\n",
    "            instructions=\"You are a helpful AI assistant.\",\n",
    "            tools=get_weather,\n",
    "            # No middleware at agent level\n",
    "        ) as agent,\n",
    "    ):\n",
    "        # Scenario 1: Run without any middleware\n",
    "        print(\"\\n--- Scenario 1: No Middleware ---\")\n",
    "        query = \"What's the weather in Tokyo?\"\n",
    "        print(f\"User: {query}\")\n",
    "        result = await agent.run(query)\n",
    "        print(f\"Response: {result.text if result.text else 'No response'}\")\n",
    "\n",
    "        # Scenario 2: Run with specific middleware for this call only (both enhancement and security)\n",
    "        print(\"\\n--- Scenario 2: With Run-level Middleware ---\")\n",
    "        print(f\"User: {query}\")\n",
    "        result = await agent.run(\n",
    "            query,\n",
    "            middleware=[\n",
    "                InputObserverMiddleware(replacement=\"What's the weather in Madrid?\"),\n",
    "                security_and_override_middleware,\n",
    "            ],\n",
    "        )\n",
    "        print(f\"Response: {result.text if result.text else 'No response'}\")\n",
    "\n",
    "        # Scenario 3: Security test with run-level middleware\n",
    "        print(\"\\n--- Scenario 3: Security Test with Run-level Middleware ---\")\n",
    "        query = \"Can you help me with my secret API key?\"\n",
    "        print(f\"User: {query}\")\n",
    "        result = await agent.run(\n",
    "            query,\n",
    "            middleware=security_and_override_middleware,\n",
    "        )\n",
    "        print(f\"Response: {result.text if result.text else 'No response'}\")\n",
    "\n",
    "await run_level_middleware()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- Chat middleware intercepts messages before they reach the AI\n",
    "- Can observe, modify, or override chat interactions\n",
    "- Class-based middleware inherits from ChatMiddleware\n",
    "- Function-based middleware uses @chat_middleware decorator\n",
    "- Agent-level middleware applies to all runs\n",
    "- Run-level middleware applies to specific runs only\n",
    "- Useful for security filtering, content policies, and logging\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- **Exception handling** (notebook 6) for error management\n",
    "- **Middleware termination** (notebook 7) for early exit scenarios"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}