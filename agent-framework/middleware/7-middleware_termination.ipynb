{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Middleware Termination\n",
    "\n",
    "This notebook demonstrates how middleware can terminate the execution pipeline early.\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "- **Early Exit**: Stop processing without calling next middleware\n",
    "- **Conditional Execution**: Only proceed if certain conditions are met\n",
    "- **Short-Circuiting**: Return cached or default results immediately\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Azure OpenAI endpoint and deployment configured in `.env`\n",
    "- `agent-framework` package installed\n",
    "- Azure CLI authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../.env')\n",
    "\n",
    "project_endpoint = os.getenv(\"AZURE_AI_PROJECT_ENDPOINT\")\n",
    "model_deployment_name = os.getenv(\"AZURE_AI_MODEL_DEPLOYMENT_NAME\")\n",
    "\n",
    "print(f\"Project Endpoint: {project_endpoint}\")\n",
    "print(f\"Model Deployment: {model_deployment_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Awaitable, Callable\n",
    "from random import randint\n",
    "from typing import Annotated\n",
    "\n",
    "from agent_framework import (\n",
    "    AgentMiddleware,\n",
    "    AgentRunContext,\n",
    "    AgentRunResponse,\n",
    "    ChatMessage,\n",
    "    Role,\n",
    ")\n",
    "from agent_framework.azure import AzureAIAgentClient\n",
    "from azure.identity.aio import AzureCliCredential\n",
    "from pydantic import Field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Weather Tool Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(\n",
    "    location: Annotated[str, Field(description=\"The location to get the weather for.\")],\n",
    ") -> str:\n",
    "    \"\"\"Get the weather for a given location.\"\"\"\n",
    "    conditions = [\"sunny\", \"cloudy\", \"rainy\", \"stormy\"]\n",
    "    return f\"The weather in {location} is {conditions[randint(0, 3)]} with a high of {randint(10, 30)}\u00b0C.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Termination Middleware\n",
    "\n",
    "This sample demonstrates how middleware can terminate execution using the `context.terminate` flag.\n",
    "\n",
    "**PreTerminationMiddleware**: Terminates execution before processing to prevent agent from running (e.g., security checks, blocked words)\n",
    "\n",
    "**PostTerminationMiddleware**: Allows processing to complete but terminates further execution (e.g., rate limiting, max responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreTerminationMiddleware(AgentMiddleware):\n",
    "    \"\"\"Middleware that terminates execution before calling the agent.\"\"\"\n",
    "\n",
    "    def __init__(self, blocked_words: list[str]):\n",
    "        self.blocked_words = [word.lower() for word in blocked_words]\n",
    "\n",
    "    async def process(\n",
    "        self,\n",
    "        context: AgentRunContext,\n",
    "        next: Callable[[AgentRunContext], Awaitable[None]],\n",
    "    ) -> None:\n",
    "        # Check if the user message contains any blocked words\n",
    "        last_message = context.messages[-1] if context.messages else None\n",
    "        if last_message and last_message.text:\n",
    "            query = last_message.text.lower()\n",
    "            for blocked_word in self.blocked_words:\n",
    "                if blocked_word in query:\n",
    "                    print(f\"[PreTerminationMiddleware] Blocked word '{blocked_word}' detected. Terminating request.\")\n",
    "\n",
    "                    # Set a custom response\n",
    "                    context.result = AgentRunResponse(\n",
    "                        messages=[\n",
    "                            ChatMessage(\n",
    "                                role=Role.ASSISTANT,\n",
    "                                text=(\n",
    "                                    f\"Sorry, I cannot process requests containing '{blocked_word}'. \"\n",
    "                                    \"Please rephrase your question.\"\n",
    "                                ),\n",
    "                            )\n",
    "                        ]\n",
    "                    )\n",
    "\n",
    "                    # Set terminate flag to prevent further processing\n",
    "                    context.terminate = True\n",
    "                    break\n",
    "\n",
    "        await next(context)\n",
    "\n",
    "\n",
    "class PostTerminationMiddleware(AgentMiddleware):\n",
    "    \"\"\"Middleware that allows processing but terminates after reaching max responses across multiple runs.\"\"\"\n",
    "\n",
    "    def __init__(self, max_responses: int = 1):\n",
    "        self.max_responses = max_responses\n",
    "        self.response_count = 0\n",
    "\n",
    "    async def process(\n",
    "        self,\n",
    "        context: AgentRunContext,\n",
    "        next: Callable[[AgentRunContext], Awaitable[None]],\n",
    "    ) -> None:\n",
    "        print(f\"[PostTerminationMiddleware] Processing request (response count: {self.response_count})\")\n",
    "\n",
    "        # Check if we should terminate before processing\n",
    "        if self.response_count >= self.max_responses:\n",
    "            print(\n",
    "                f\"[PostTerminationMiddleware] Maximum responses ({self.max_responses}) reached. \"\n",
    "                \"Terminating further processing.\"\n",
    "            )\n",
    "            context.terminate = True\n",
    "\n",
    "        # Allow the agent to process normally\n",
    "        await next(context)\n",
    "\n",
    "        # Increment response count after processing\n",
    "        self.response_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Pre-termination Middleware (Blocked Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def pre_termination_middleware():\n",
    "    \"\"\"Demonstrate pre-termination middleware that blocks requests with certain words.\"\"\"\n",
    "    print(\"\\n--- Example 1: Pre-termination Middleware ---\")\n",
    "    \n",
    "    async with (\n",
    "        AzureCliCredential() as credential,\n",
    "        AzureAIAgentClient(async_credential=credential).create_agent(\n",
    "            name=\"WeatherAgent\",\n",
    "            instructions=\"You are a helpful weather assistant.\",\n",
    "            tools=get_weather,\n",
    "            middleware=PreTerminationMiddleware(blocked_words=[\"bad\", \"inappropriate\"]),\n",
    "        ) as agent,\n",
    "    ):\n",
    "        # Test with normal query\n",
    "        print(\"\\n1. Normal query:\")\n",
    "        query = \"What's the weather like in Seattle?\"\n",
    "        print(f\"User: {query}\")\n",
    "        result = await agent.run(query)\n",
    "        print(f\"Agent: {result.text}\")\n",
    "\n",
    "        # Test with blocked word\n",
    "        print(\"\\n2. Query with blocked word:\")\n",
    "        query = \"What's the bad weather in New York?\"\n",
    "        print(f\"User: {query}\")\n",
    "        result = await agent.run(query)\n",
    "        print(f\"Agent: {result.text}\")\n",
    "\n",
    "await pre_termination_middleware()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Post-termination Middleware (Max Responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def post_termination_middleware():\n",
    "    \"\"\"Demonstrate post-termination middleware that limits responses across multiple runs.\"\"\"\n",
    "    print(\"\\n--- Example 2: Post-termination Middleware ---\")\n",
    "    \n",
    "    async with (\n",
    "        AzureCliCredential() as credential,\n",
    "        AzureAIAgentClient(async_credential=credential).create_agent(\n",
    "            name=\"WeatherAgent\",\n",
    "            instructions=\"You are a helpful weather assistant.\",\n",
    "            tools=get_weather,\n",
    "            middleware=PostTerminationMiddleware(max_responses=1),\n",
    "        ) as agent,\n",
    "    ):\n",
    "        # First run (should work)\n",
    "        print(\"\\n1. First run:\")\n",
    "        query = \"What's the weather in Paris?\"\n",
    "        print(f\"User: {query}\")\n",
    "        result = await agent.run(query)\n",
    "        print(f\"Agent: {result.text}\")\n",
    "\n",
    "        # Second run (should be terminated by middleware)\n",
    "        print(\"\\n2. Second run (should be terminated):\")\n",
    "        query = \"What about the weather in London?\"\n",
    "        print(f\"User: {query}\")\n",
    "        result = await agent.run(query)\n",
    "        print(f\"Agent: {result.text if result.text else 'No response (terminated)'}\")\n",
    "\n",
    "        # Third run (should also be terminated)\n",
    "        print(\"\\n3. Third run (should also be terminated):\")\n",
    "        query = \"And New York?\"\n",
    "        print(f\"User: {query}\")\n",
    "        result = await agent.run(query)\n",
    "        print(f\"Agent: {result.text if result.text else 'No response (terminated)'}\")\n",
    "\n",
    "await post_termination_middleware()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "- Middleware can terminate execution by setting `context.terminate = True`\n",
    "- **Pre-termination**: Set terminate flag before calling `next()` to prevent agent processing\n",
    "- **Post-termination**: Set terminate flag after calling `next()` to limit future runs\n",
    "- Useful for security checks, rate limiting, blocked words, or access control\n",
    "- Can set custom responses when terminating using `context.result`\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- **Result override** (notebook 8) for modifying outcomes\n",
    "- **Shared state** (notebook 9) for cross-middleware communication"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}