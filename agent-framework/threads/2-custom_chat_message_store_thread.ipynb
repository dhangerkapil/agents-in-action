{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a065621",
   "metadata": {},
   "source": [
    "# Custom Chat Message Store for Multi-Turn Conversations\n",
    "\n",
    "This notebook demonstrates how to implement and use a **custom chat message store** for managing conversation threads with AI agents using the Microsoft Agent Framework.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The Agent Framework provides flexibility in how conversation history is stored and managed. While the framework includes default in-memory storage, you can implement custom storage solutions to:\n",
    "\n",
    "- **Persist conversations** to databases (SQL, NoSQL, vector stores)\n",
    "- **Integrate with external systems** for conversation management\n",
    "- **Apply custom logic** for message retention and retrieval\n",
    "- **Scale across distributed systems** with centralized storage\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "### ChatMessageStoreProtocol\n",
    "\n",
    "Custom message stores must implement the `ChatMessageStoreProtocol`, which defines:\n",
    "- `add_messages()`: Store new messages in the conversation\n",
    "- `list_messages()`: Retrieve conversation history\n",
    "- `serialize_state()`: Convert store state to a serializable format\n",
    "- `deserialize_state()`: Restore store state from serialized data\n",
    "\n",
    "### Thread Serialization\n",
    "\n",
    "For in-memory threads with custom stores:\n",
    "- The serialized thread contains the **complete message history**\n",
    "- Allows conversation context to be saved and resumed across sessions\n",
    "- Useful for stateless applications or conversation backups\n",
    "\n",
    "## 📖 Documentation\n",
    "\n",
    "For more details, see the official documentation:\n",
    "- [Multi-Turn Conversations](https://learn.microsoft.com/en-us/agent-framework/user-guide/agents/multi-turn-conversation?pivots=programming-language-python)\n",
    "- [Custom Message Stores](https://learn.microsoft.com/en-us/agent-framework/user-guide/agents/multi-turn-conversation?pivots=programming-language-python#custom-message-stores)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bcc02b",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, ensure you have:\n",
    "1. **Environment variables configured** in `agent-framework/.env`\n",
    "2. **OpenAI API key** set (or other chat client credentials)\n",
    "3. **Required packages installed** (see imports below)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d2e20b",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "621c8a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import asyncio\n",
    "from collections.abc import Collection\n",
    "from typing import Any\n",
    "\n",
    "from agent_framework import ChatMessage, ChatMessageStoreProtocol\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e19f2395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables loaded:\n",
      "  OPENAI_API_KEY: ✓ Set\n",
      "  OPENAI_CHAT_MODEL_ID: gpt-4o\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from agent-framework/.env\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from the agent-framework directory\n",
    "env_path = Path(__file__).parent.parent / \".env\" if \"__file__\" in globals() else Path(\"../.env\")\n",
    "load_dotenv(env_path)\n",
    "\n",
    "# Verify key environment variables are loaded\n",
    "print(\"Environment variables loaded:\")\n",
    "print(f\"  OPENAI_API_KEY: {'✓ Set' if os.getenv('OPENAI_API_KEY') else '✗ Not set'}\")\n",
    "print(f\"  OPENAI_CHAT_MODEL_ID: {os.getenv('OPENAI_CHAT_MODEL_ID', 'Not set - using gpt-4o as default')}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cb4cae",
   "metadata": {},
   "source": [
    "## Implementing a Custom Chat Message Store\n",
    "\n",
    "We'll create a custom message store that demonstrates the pattern. In production, you would replace the in-memory list with actual database calls (e.g., PostgreSQL, MongoDB, Cosmos DB, or a vector database).\n",
    "\n",
    "### State Model\n",
    "\n",
    "First, we define a Pydantic model to represent the serializable state of our store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "daf36dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomStoreState(BaseModel):\n",
    "    \"\"\"Implementation of custom chat message store state.\n",
    "    \n",
    "    This model defines what gets serialized when saving the conversation state.\n",
    "    In a production system, this could include additional metadata like:\n",
    "    - User ID\n",
    "    - Session information\n",
    "    - Timestamps\n",
    "    - Custom tags or categories\n",
    "    \"\"\"\n",
    "    model_config = {\"arbitrary_types_allowed\": True}\n",
    "    \n",
    "    messages: list[ChatMessage]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea91756",
   "metadata": {},
   "source": [
    "### Custom Store Implementation\n",
    "\n",
    "Now we implement the `ChatMessageStoreProtocol` with our custom logic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54e600c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomChatMessageStore(ChatMessageStoreProtocol):\n",
    "    \"\"\"Implementation of custom chat message store.\n",
    "    \n",
    "    In real applications, this can be an implementation of:\n",
    "    - Relational database (PostgreSQL, MySQL, SQL Server)\n",
    "    - NoSQL database (MongoDB, Cosmos DB, DynamoDB)\n",
    "    - Vector store (Pinecone, Weaviate, Azure AI Search)\n",
    "    - File storage (Azure Blob, S3)\n",
    "    \n",
    "    This example uses an in-memory list for demonstration purposes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, messages: Collection[ChatMessage] | None = None) -> None:\n",
    "        \"\"\"Initialize the message store.\n",
    "        \n",
    "        Args:\n",
    "            messages: Optional initial messages to populate the store\n",
    "        \"\"\"\n",
    "        self._messages: list[ChatMessage] = []\n",
    "        if messages:\n",
    "            self._messages.extend(messages)\n",
    "\n",
    "    async def add_messages(self, messages: Collection[ChatMessage]) -> None:\n",
    "        \"\"\"Add new messages to the store.\n",
    "        \n",
    "        In a production implementation, this would:\n",
    "        - Insert messages into a database\n",
    "        - Handle connection pooling\n",
    "        - Implement retry logic\n",
    "        - Add error handling\n",
    "        \n",
    "        Args:\n",
    "            messages: Collection of messages to add\n",
    "        \"\"\"\n",
    "        self._messages.extend(messages)\n",
    "\n",
    "    async def list_messages(self) -> list[ChatMessage]:\n",
    "        \"\"\"Retrieve all messages from the store.\n",
    "        \n",
    "        In a production implementation, this would:\n",
    "        - Query the database\n",
    "        - Implement pagination for large conversations\n",
    "        - Apply filtering or sorting\n",
    "        \n",
    "        Returns:\n",
    "            List of all stored messages\n",
    "        \"\"\"\n",
    "        return self._messages\n",
    "\n",
    "    async def deserialize_state(self, serialized_store_state: Any, **kwargs: Any) -> None:\n",
    "        \"\"\"Restore the store state from serialized data.\n",
    "        \n",
    "        This method is called when resuming a conversation from saved state.\n",
    "        \n",
    "        Args:\n",
    "            serialized_store_state: Previously serialized state data\n",
    "            **kwargs: Additional arguments for deserialization\n",
    "        \"\"\"\n",
    "        if serialized_store_state:\n",
    "            state = CustomStoreState.model_validate(serialized_store_state, **kwargs)\n",
    "            if state.messages:\n",
    "                self._messages.extend(state.messages)\n",
    "\n",
    "    async def serialize_state(self, **kwargs: Any) -> Any:\n",
    "        \"\"\"Serialize the current store state.\n",
    "        \n",
    "        This method is called when saving a conversation for later use.\n",
    "        \n",
    "        Args:\n",
    "            **kwargs: Additional arguments for serialization\n",
    "            \n",
    "        Returns:\n",
    "            Serialized state as a dictionary\n",
    "        \"\"\"\n",
    "        state = CustomStoreState(messages=self._messages)\n",
    "        return state.model_dump(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d2c587",
   "metadata": {},
   "source": [
    "## Using the Custom Message Store\n",
    "\n",
    "Now let's see how to use our custom message store with an AI agent. This example demonstrates:\n",
    "\n",
    "1. **Creating an agent** with a custom message store factory\n",
    "2. **Starting a conversation thread** using the custom store\n",
    "3. **Serializing the thread** to save conversation state\n",
    "4. **Deserializing the thread** to resume the conversation\n",
    "\n",
    "### Agent Creation with Custom Store\n",
    "\n",
    "We pass a factory function to the agent that creates instances of our custom store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a9ae4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def demonstrate_custom_store():\n",
    "    \"\"\"Demonstrates how to use 3rd party or custom chat message store for threads.\"\"\"\n",
    "    from openai import AsyncAzureOpenAI\n",
    "    from agent_framework.openai import OpenAIChatClient\n",
    "    \n",
    "    print(\"=== Thread with Custom Chat Message Store ===\")\n",
    "    print()\n",
    "    print(\"📌 Using Azure OpenAI for this example.\")\n",
    "    print()\n",
    "\n",
    "    # Create Azure OpenAI async client\n",
    "    azure_client = AsyncAzureOpenAI(\n",
    "        api_key=os.getenv(\"AZURE_OPENAI_API_KEY\") or os.getenv(\"OPENAI_API_KEY\"),\n",
    "        api_version=\"2024-10-21\",\n",
    "        azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    )\n",
    "    \n",
    "    # Create an agent with Azure OpenAI client and custom message store factory\n",
    "    agent = OpenAIChatClient(\n",
    "        model_id=os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\", \"gpt-4o\"),\n",
    "        async_client=azure_client\n",
    "    ).create_agent(\n",
    "        name=\"Joker\",\n",
    "        instructions=\"You are good at telling jokes.\",\n",
    "        # Use custom chat message store.\n",
    "        # If not provided, the default in-memory store will be used.\n",
    "        chat_message_store_factory=CustomChatMessageStore,\n",
    "    )\n",
    "\n",
    "    print(\"✓ Agent created with custom message store\")\n",
    "    print()\n",
    "    \n",
    "    # Start a new thread for the agent conversation.\n",
    "    # This will create a new instance of CustomChatMessageStore\n",
    "    thread = agent.get_new_thread()\n",
    "    \n",
    "    print(\"✓ New thread created\")\n",
    "    print()\n",
    "\n",
    "    # --- Phase 1: Initial Conversation ---\n",
    "    print(\"--- Phase 1: Initial Conversation ---\")\n",
    "    print()\n",
    "    \n",
    "    query = \"Tell me a joke about a pirate.\"\n",
    "    print(f\"User: {query}\")\n",
    "    response = await agent.run(query, thread=thread)\n",
    "    print(f\"Agent: {response}\")\n",
    "    print()\n",
    "\n",
    "    # --- Phase 2: Suspend (Serialize) ---\n",
    "    print(\"--- Phase 2: Suspending Conversation ---\")\n",
    "    print()\n",
    "    \n",
    "    # Serialize the thread state, so it can be stored for later use.\n",
    "    # For custom stores, this includes the entire message history\n",
    "    serialized_thread = await thread.serialize()\n",
    "\n",
    "    print(\"📦 Serialized thread (first 200 chars):\")\n",
    "    print(f\"   {str(serialized_thread)[:200]}...\")\n",
    "    print()\n",
    "    print(\"💾 The thread can now be saved to:\")\n",
    "    print(\"   - Database (PostgreSQL, MongoDB, etc.)\")\n",
    "    print(\"   - File storage (JSON, Azure Blob, S3)\")\n",
    "    print(\"   - Cache (Redis, Memcached)\")\n",
    "    print(\"   - Any other storage mechanism\")\n",
    "    print()\n",
    "\n",
    "    # Simulate loading the thread from storage and resuming the conversation\n",
    "    print(\"--- Phase 3: Resuming Conversation ---\")\n",
    "    print()\n",
    "    \n",
    "    # Deserialize the thread state after loading from storage.\n",
    "    # This creates a new thread with the same conversation history\n",
    "    resumed_thread = await agent.deserialize_thread(serialized_thread)\n",
    "    \n",
    "    print(\"✓ Thread deserialized and conversation context restored\")\n",
    "    print()\n",
    "\n",
    "    # Continue the conversation - the agent remembers the previous joke\n",
    "    query = \"Now tell the same joke in the voice of a pirate, and add some emojis to the joke.\"\n",
    "    print(f\"User: {query}\")\n",
    "    response = await agent.run(query, thread=resumed_thread)\n",
    "    print(f\"Agent: {response}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"✅ Conversation resumed successfully with full context!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf001a90",
   "metadata": {},
   "source": [
    "## Run the Demo\n",
    "\n",
    "Execute the demonstration to see the custom message store in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50c0dfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Thread with Custom Chat Message Store ===\n",
      "\n",
      "📌 Using Azure OpenAI for this example.\n",
      "\n",
      "✓ Agent created with custom message store\n",
      "\n",
      "✓ New thread created\n",
      "\n",
      "--- Phase 1: Initial Conversation ---\n",
      "\n",
      "User: Tell me a joke about a pirate.\n",
      "✓ Agent created with custom message store\n",
      "\n",
      "✓ New thread created\n",
      "\n",
      "--- Phase 1: Initial Conversation ---\n",
      "\n",
      "User: Tell me a joke about a pirate.\n",
      "Agent: Why did the pirate go to the gym?  \n",
      "\n",
      "To improve his **plank**! 🏴‍☠️\n",
      "\n",
      "--- Phase 2: Suspending Conversation ---\n",
      "\n",
      "📦 Serialized thread (first 200 chars):\n",
      "   {'service_thread_id': None, 'chat_message_store_state': None}...\n",
      "\n",
      "💾 The thread can now be saved to:\n",
      "   - Database (PostgreSQL, MongoDB, etc.)\n",
      "   - File storage (JSON, Azure Blob, S3)\n",
      "   - Cache (Redis, Memcached)\n",
      "   - Any other storage mechanism\n",
      "\n",
      "--- Phase 3: Resuming Conversation ---\n",
      "\n",
      "✓ Thread deserialized and conversation context restored\n",
      "\n",
      "User: Now tell the same joke in the voice of a pirate, and add some emojis to the joke.\n",
      "Agent: Why did the pirate go to the gym?  \n",
      "\n",
      "To improve his **plank**! 🏴‍☠️\n",
      "\n",
      "--- Phase 2: Suspending Conversation ---\n",
      "\n",
      "📦 Serialized thread (first 200 chars):\n",
      "   {'service_thread_id': None, 'chat_message_store_state': None}...\n",
      "\n",
      "💾 The thread can now be saved to:\n",
      "   - Database (PostgreSQL, MongoDB, etc.)\n",
      "   - File storage (JSON, Azure Blob, S3)\n",
      "   - Cache (Redis, Memcached)\n",
      "   - Any other storage mechanism\n",
      "\n",
      "--- Phase 3: Resuming Conversation ---\n",
      "\n",
      "✓ Thread deserialized and conversation context restored\n",
      "\n",
      "User: Now tell the same joke in the voice of a pirate, and add some emojis to the joke.\n",
      "Agent: Alright, matey! Here’s a pirate version of a joke fer ye, with some emoji flair! 🏴‍☠️⚓️👀\n",
      "\n",
      "Why did the pirate 👨‍✈️🔎 refuse t' finish his alphabet?  \n",
      "Because he always gets stuck at \"R\"! 🏴‍☠️ Arrrr! 😂\n",
      "\n",
      "✅ Conversation resumed successfully with full context!\n",
      "Agent: Alright, matey! Here’s a pirate version of a joke fer ye, with some emoji flair! 🏴‍☠️⚓️👀\n",
      "\n",
      "Why did the pirate 👨‍✈️🔎 refuse t' finish his alphabet?  \n",
      "Because he always gets stuck at \"R\"! 🏴‍☠️ Arrrr! 😂\n",
      "\n",
      "✅ Conversation resumed successfully with full context!\n"
     ]
    }
   ],
   "source": [
    "# Run the demonstration\n",
    "await demonstrate_custom_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307283ae",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "1. **Custom Storage Flexibility**: Implement `ChatMessageStoreProtocol` to integrate with any storage backend\n",
    "\n",
    "2. **Factory Pattern**: Use `chat_message_store_factory` to provide custom store instances for each thread\n",
    "\n",
    "3. **Full Serialization**: For in-memory custom stores, serialized threads contain complete message history\n",
    "\n",
    "4. **Production Considerations**:\n",
    "   - Add database connection pooling\n",
    "   - Implement error handling and retries\n",
    "   - Consider message pagination for large conversations\n",
    "   - Add indexes for efficient querying\n",
    "   - Implement data retention policies\n",
    "\n",
    "5. **Use Cases**:\n",
    "   - Multi-tenant applications with isolated storage\n",
    "   - Compliance requirements for conversation auditing\n",
    "   - Integration with existing data infrastructure\n",
    "   - Advanced analytics on conversation patterns\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Explore **[Redis Chat Message Store](3-redis_chat_message_store_thread.ipynb)** for distributed scenarios\n",
    "- Learn about **[Thread Suspend/Resume](4-suspend_resume_thread.ipynb)** patterns\n",
    "- Review **[Multi-Turn Conversation Documentation](https://learn.microsoft.com/en-us/agent-framework/user-guide/agents/multi-turn-conversation?pivots=programming-language-python)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
