{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d46dad30",
   "metadata": {},
   "source": [
    "# Sub-Workflow Basics\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates **sub-workflow composition** - showing how parent workflows orchestrate and collect results from embedded sub-workflows using `WorkflowExecutor`.\n",
    "\n",
    "### Text Processing Pipeline:\n",
    "\n",
    "```\n",
    "Parent Workflow:\n",
    "  TextProcessingOrchestrator (start)\n",
    "      |\n",
    "      | Dispatches TextProcessingRequest x6 (concurrent)\n",
    "      v\n",
    "  [ Sub-Workflow: WorkflowExecutor(TextProcessor) ]\n",
    "      |\n",
    "      | Each sub-workflow: counts words & characters\n",
    "      v\n",
    "  TextProcessingOrchestrator (collect_result)\n",
    "      |\n",
    "      | When all results collected\n",
    "      v\n",
    "  AllTasksCompleted event\n",
    "```\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "1. **WorkflowExecutor**: Embed complete workflows as executors\n",
    "2. **Sub-Workflow Isolation**: Each sub-workflow processes independently\n",
    "3. **Result Collection**: Parent aggregates outputs from multiple sub-workflows\n",
    "4. **Yield Output**: Sub-workflows signal completion via `ctx.yield_output()`\n",
    "5. **Concurrent Processing**: Multiple sub-workflows run in parallel\n",
    "6. **Custom Events**: AllTasksCompleted signals batch completion\n",
    "\n",
    "### What You Learn:\n",
    "\n",
    "- Create sub-workflows with `WorkflowBuilder`\n",
    "- Embed sub-workflows using `WorkflowExecutor`\n",
    "- Dispatch concurrent tasks to sub-workflows\n",
    "- Collect and aggregate sub-workflow results\n",
    "- Use custom events for workflow coordination\n",
    "- Build reusable workflow components\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Agent Framework installed: `pip install agent-framework`\n",
    "- No external services required"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3125130f",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29de46ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from dataclasses import dataclass\n",
    "from typing import Any\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from agent_framework import (\n",
    "    Executor,\n",
    "    WorkflowBuilder,\n",
    "    WorkflowContext,\n",
    "    WorkflowEvent,\n",
    "    WorkflowExecutor,\n",
    "    handler,\n",
    ")\n",
    "from typing_extensions import Never\n",
    "# Load environment variables from .env file\n",
    "load_dotenv('../../.env')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820e1ccb",
   "metadata": {},
   "source": [
    "## Define Message Types\n",
    "\n",
    "### Message Flow:\n",
    "\n",
    "```\n",
    "TextProcessingRequest\n",
    "    ↓ (to sub-workflow)\n",
    "Sub-workflow processes\n",
    "    ↓\n",
    "TextProcessingResult\n",
    "    ↓ (yielded back to parent)\n",
    "Parent collects results\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2ce049",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TextProcessingRequest:\n",
    "    \"\"\"Request to process a text string.\"\"\"\n",
    "    text: str\n",
    "    task_id: str\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TextProcessingResult:\n",
    "    \"\"\"Result of text processing.\"\"\"\n",
    "    task_id: str\n",
    "    text: str\n",
    "    word_count: int\n",
    "    char_count: int\n",
    "\n",
    "\n",
    "class AllTasksCompleted(WorkflowEvent):\n",
    "    \"\"\"Event triggered when all processing tasks are complete.\"\"\"\n",
    "    def __init__(self, results: list[TextProcessingResult]):\n",
    "        super().__init__(results)\n",
    "\n",
    "\n",
    "print(\"✓ Message types defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c06cbbd",
   "metadata": {},
   "source": [
    "## Create Sub-Workflow Executor\n",
    "\n",
    "### TextProcessor\n",
    "\n",
    "**Demonstrates:**\n",
    "- Simple text analysis (word count, character count)\n",
    "- Sub-workflow completion with `yield_output()`\n",
    "- Task identification for result correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2ff84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextProcessor(Executor):\n",
    "    \"\"\"Processes text strings - counts words and characters.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(id=\"text_processor\")\n",
    "\n",
    "    @handler\n",
    "    async def process_text(\n",
    "        self, \n",
    "        request: TextProcessingRequest, \n",
    "        ctx: WorkflowContext[Never, TextProcessingResult]\n",
    "    ) -> None:\n",
    "        \"\"\"Process a text string and return statistics.\"\"\"\n",
    "        text_preview = f\"'{request.text[:50]}{'...' if len(request.text) > 50 else ''}'\"\n",
    "        print(f\"🔍 Sub-workflow processing text (Task {request.task_id}): {text_preview}\")\n",
    "\n",
    "        # Simple text processing\n",
    "        word_count = len(request.text.split()) if request.text.strip() else 0\n",
    "        char_count = len(request.text)\n",
    "\n",
    "        print(f\"📊 Task {request.task_id}: {word_count} words, {char_count} characters\")\n",
    "\n",
    "        # Create result\n",
    "        result = TextProcessingResult(\n",
    "            task_id=request.task_id,\n",
    "            text=request.text,\n",
    "            word_count=word_count,\n",
    "            char_count=char_count,\n",
    "        )\n",
    "\n",
    "        print(f\"✅ Sub-workflow completed task {request.task_id}\")\n",
    "        # Signal completion by yielding the result\n",
    "        await ctx.yield_output(result)\n",
    "\n",
    "\n",
    "print(\"✓ TextProcessor executor created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1456caf9",
   "metadata": {},
   "source": [
    "## Create Parent Workflow Executor\n",
    "\n",
    "### TextProcessingOrchestrator\n",
    "\n",
    "**Demonstrates:**\n",
    "- Concurrent task dispatching to sub-workflows\n",
    "- Result collection and aggregation\n",
    "- Custom event emission when batch completes\n",
    "- Summary statistics calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dbc268",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextProcessingOrchestrator(Executor):\n",
    "    \"\"\"Orchestrates multiple text processing tasks using sub-workflows.\"\"\"\n",
    "\n",
    "    results: list[TextProcessingResult] = []\n",
    "    expected_count: int = 0\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(id=\"text_orchestrator\")\n",
    "\n",
    "    @handler\n",
    "    async def start_processing(\n",
    "        self, \n",
    "        texts: list[str], \n",
    "        ctx: WorkflowContext[TextProcessingRequest]\n",
    "    ) -> None:\n",
    "        \"\"\"Start processing multiple text strings.\"\"\"\n",
    "        print(f\"📄 Starting processing of {len(texts)} text strings\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        self.expected_count = len(texts)\n",
    "\n",
    "        # Send each text to a sub-workflow\n",
    "        for i, text in enumerate(texts):\n",
    "            task_id = f\"task_{i + 1}\"\n",
    "            request = TextProcessingRequest(text=text, task_id=task_id)\n",
    "            print(f\"📤 Dispatching {task_id} to sub-workflow\")\n",
    "            await ctx.send_message(request, target_id=\"text_processor_workflow\")\n",
    "\n",
    "    @handler\n",
    "    async def collect_result(\n",
    "        self, \n",
    "        result: TextProcessingResult, \n",
    "        ctx: WorkflowContext\n",
    "    ) -> None:\n",
    "        \"\"\"Collect results from sub-workflows.\"\"\"\n",
    "        print(f\"📥 Collected result from {result.task_id}\")\n",
    "        self.results.append(result)\n",
    "\n",
    "        # Check if all results are collected\n",
    "        if len(self.results) == self.expected_count:\n",
    "            print(\"\\n🎉 All tasks completed!\")\n",
    "            await ctx.add_event(AllTasksCompleted(self.results))\n",
    "\n",
    "    def get_summary(self) -> dict[str, Any]:\n",
    "        \"\"\"Get a summary of all processing results.\"\"\"\n",
    "        total_words = sum(result.word_count for result in self.results)\n",
    "        total_chars = sum(result.char_count for result in self.results)\n",
    "        avg_words = total_words / len(self.results) if self.results else 0\n",
    "        avg_chars = total_chars / len(self.results) if self.results else 0\n",
    "\n",
    "        return {\n",
    "            \"total_texts\": len(self.results),\n",
    "            \"total_words\": total_words,\n",
    "            \"total_characters\": total_chars,\n",
    "            \"average_words_per_text\": round(avg_words, 2),\n",
    "            \"average_characters_per_text\": round(avg_chars, 2),\n",
    "        }\n",
    "\n",
    "\n",
    "print(\"✓ TextProcessingOrchestrator executor created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68069143",
   "metadata": {},
   "source": [
    "## Build Workflows\n",
    "\n",
    "### Sub-Workflow:\n",
    "\n",
    "```\n",
    "TextProcessor (start) → yield_output(result)\n",
    "```\n",
    "\n",
    "### Parent Workflow:\n",
    "\n",
    "```\n",
    "TextProcessingOrchestrator (start)\n",
    "    ↓\n",
    "WorkflowExecutor(processing_workflow)\n",
    "    ↓\n",
    "TextProcessingOrchestrator (collect_result)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b49d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create the text processing sub-workflow\n",
    "print(\"🚀 Setting up sub-workflow...\")\n",
    "text_processor = TextProcessor()\n",
    "\n",
    "processing_workflow = (\n",
    "    WorkflowBuilder()\n",
    "    .set_start_executor(text_processor)\n",
    "    .build()\n",
    ")\n",
    "\n",
    "print(\"✓ Sub-workflow created\")\n",
    "\n",
    "# Step 2: Create the parent workflow\n",
    "print(\"🔧 Setting up parent workflow...\")\n",
    "orchestrator = TextProcessingOrchestrator()\n",
    "workflow_executor = WorkflowExecutor(processing_workflow, id=\"text_processor_workflow\")\n",
    "\n",
    "main_workflow = (\n",
    "    WorkflowBuilder()\n",
    "    .set_start_executor(orchestrator)\n",
    "    .add_edge(orchestrator, workflow_executor)\n",
    "    .add_edge(workflow_executor, orchestrator)\n",
    "    .build()\n",
    ")\n",
    "\n",
    "print(\"✓ Parent workflow created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6df25d",
   "metadata": {},
   "source": [
    "## Prepare Test Data\n",
    "\n",
    "Testing with 6 different text samples:\n",
    "1. Simple sentence\n",
    "2. Complex sentence\n",
    "3. Short text\n",
    "4. Long multi-sentence text\n",
    "5. Empty string (edge case)\n",
    "6. Text with extra spaces (edge case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0b6363",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = [\n",
    "    \"Hello world! This is a simple test.\",\n",
    "    \"Python is a powerful programming language used for many applications.\",\n",
    "    \"Short text.\",\n",
    "    \"This is a longer text with multiple sentences. It contains more words and characters. We use it to test our text processing workflow.\",\n",
    "    \"\",  # Empty string\n",
    "    \"   Spaces   around   text   \",\n",
    "]\n",
    "\n",
    "print(f\"✓ Prepared {len(test_texts)} test texts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7224ec49",
   "metadata": {},
   "source": [
    "## Run Workflow\n",
    "\n",
    "Watch as:\n",
    "1. Orchestrator dispatches 6 tasks concurrently\n",
    "2. Each sub-workflow processes independently\n",
    "3. Results are collected as they complete\n",
    "4. AllTasksCompleted event fires when all done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f231fccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n🧪 Testing with {len(test_texts)} text strings\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "await main_workflow.run(test_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804559c7",
   "metadata": {},
   "source": [
    "## Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd7b00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📊 Processing Results:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Sort results by task_id for consistent display\n",
    "sorted_results = sorted(orchestrator.results, key=lambda r: r.task_id)\n",
    "\n",
    "for result in sorted_results:\n",
    "    preview = result.text[:30] + \"...\" if len(result.text) > 30 else result.text\n",
    "    preview = preview.replace(\"\\n\", \" \").strip() or \"(empty)\"\n",
    "    print(f\"✅ {result.task_id}: '{preview}' -> {result.word_count} words, {result.char_count} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214a6917",
   "metadata": {},
   "source": [
    "## Display Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077d4d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = orchestrator.get_summary()\n",
    "\n",
    "print(\"\\n📈 Summary:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"📄 Total texts processed: {summary['total_texts']}\")\n",
    "print(f\"📝 Total words: {summary['total_words']}\")\n",
    "print(f\"🔤 Total characters: {summary['total_characters']}\")\n",
    "print(f\"📊 Average words per text: {summary['average_words_per_text']}\")\n",
    "print(f\"📏 Average characters per text: {summary['average_characters_per_text']}\")\n",
    "\n",
    "print(\"\\n🏁 Processing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4153731",
   "metadata": {},
   "source": [
    "## Expected Output Pattern\n",
    "\n",
    "```\n",
    "🚀 Setting up sub-workflow...\n",
    "✓ Sub-workflow created\n",
    "🔧 Setting up parent workflow...\n",
    "✓ Parent workflow created\n",
    "\n",
    "🧪 Testing with 6 text strings\n",
    "============================================================\n",
    "📄 Starting processing of 6 text strings\n",
    "============================================================\n",
    "📤 Dispatching task_1 to sub-workflow\n",
    "📤 Dispatching task_2 to sub-workflow\n",
    "📤 Dispatching task_3 to sub-workflow\n",
    "📤 Dispatching task_4 to sub-workflow\n",
    "📤 Dispatching task_5 to sub-workflow\n",
    "📤 Dispatching task_6 to sub-workflow\n",
    "🔍 Sub-workflow processing text (Task task_1): 'Hello world! This is a simple test.'\n",
    "📊 Task task_1: 6 words, 35 characters\n",
    "✅ Sub-workflow completed task task_1\n",
    "📥 Collected result from task_1\n",
    "🔍 Sub-workflow processing text (Task task_2): 'Python is a powerful programming language used...'\n",
    "📊 Task task_2: 10 words, 68 characters\n",
    "✅ Sub-workflow completed task task_2\n",
    "📥 Collected result from task_2\n",
    "🔍 Sub-workflow processing text (Task task_3): 'Short text.'\n",
    "📊 Task task_3: 2 words, 11 characters\n",
    "✅ Sub-workflow completed task task_3\n",
    "📥 Collected result from task_3\n",
    "🔍 Sub-workflow processing text (Task task_4): 'This is a longer text with multiple sentences...'\n",
    "📊 Task task_4: 24 words, 139 characters\n",
    "✅ Sub-workflow completed task task_4\n",
    "📥 Collected result from task_4\n",
    "🔍 Sub-workflow processing text (Task task_5): ''\n",
    "📊 Task task_5: 0 words, 0 characters\n",
    "✅ Sub-workflow completed task task_5\n",
    "📥 Collected result from task_5\n",
    "🔍 Sub-workflow processing text (Task task_6): '   Spaces   around   text   '\n",
    "📊 Task task_6: 3 words, 28 characters\n",
    "✅ Sub-workflow completed task task_6\n",
    "📥 Collected result from task_6\n",
    "\n",
    "🎉 All tasks completed!\n",
    "\n",
    "📊 Processing Results:\n",
    "============================================================\n",
    "✅ task_1: 'Hello world! This is a simp...' -> 6 words, 35 chars\n",
    "✅ task_2: 'Python is a powerful program...' -> 10 words, 68 chars\n",
    "✅ task_3: 'Short text.' -> 2 words, 11 chars\n",
    "✅ task_4: 'This is a longer text with m...' -> 24 words, 139 chars\n",
    "✅ task_5: '(empty)' -> 0 words, 0 chars\n",
    "✅ task_6: 'Spaces   around   text' -> 3 words, 28 chars\n",
    "\n",
    "📈 Summary:\n",
    "============================================================\n",
    "📄 Total texts processed: 6\n",
    "📝 Total words: 45\n",
    "🔤 Total characters: 281\n",
    "📊 Average words per text: 7.5\n",
    "📏 Average characters per text: 46.83\n",
    "\n",
    "🏁 Processing complete!\n",
    "```\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "### 1. WorkflowExecutor Pattern\n",
    "\n",
    "```python\n",
    "# Create sub-workflow\n",
    "sub_workflow = WorkflowBuilder().set_start_executor(processor).build()\n",
    "\n",
    "# Embed in parent as executor\n",
    "workflow_executor = WorkflowExecutor(sub_workflow, id=\"sub_workflow_id\")\n",
    "\n",
    "# Use in parent graph\n",
    "parent = (\n",
    "    WorkflowBuilder()\n",
    "    .set_start_executor(orchestrator)\n",
    "    .add_edge(orchestrator, workflow_executor)\n",
    "    .add_edge(workflow_executor, orchestrator)  # Results back to parent\n",
    "    .build()\n",
    ")\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "- Workflow reusability\n",
    "- Clear separation of concerns\n",
    "- Independent testing\n",
    "- Modular composition\n",
    "\n",
    "### 2. Sub-Workflow Completion\n",
    "\n",
    "```python\n",
    "# In sub-workflow executor\n",
    "@handler\n",
    "async def process(self, request: Request, ctx: WorkflowContext[Never, Result]) -> None:\n",
    "    result = do_processing(request)\n",
    "    \n",
    "    # Signal completion and return result to parent\n",
    "    await ctx.yield_output(result)\n",
    "```\n",
    "\n",
    "**Key Points:**\n",
    "- `yield_output()` sends result to parent workflow\n",
    "- Sub-workflow completes after yielding\n",
    "- Parent receives result via handler\n",
    "- Multiple yields create multiple results\n",
    "\n",
    "### 3. Concurrent Task Dispatching\n",
    "\n",
    "```python\n",
    "@handler\n",
    "async def start_processing(self, items: list[str], ctx) -> None:\n",
    "    for i, item in enumerate(items):\n",
    "        request = ProcessingRequest(data=item, id=f\"task_{i}\")\n",
    "        # All sent concurrently - not awaited\n",
    "        await ctx.send_message(request, target_id=\"sub_workflow\")\n",
    "```\n",
    "\n",
    "**Execution Model:**\n",
    "- Messages sent without blocking\n",
    "- Sub-workflows process in parallel\n",
    "- Results arrive asynchronously\n",
    "- Parent handles each result independently\n",
    "\n",
    "### 4. Result Collection Pattern\n",
    "\n",
    "```python\n",
    "class Orchestrator(Executor):\n",
    "    results: list[Result] = []\n",
    "    expected_count: int = 0\n",
    "    \n",
    "    @handler\n",
    "    async def start(self, items: list, ctx) -> None:\n",
    "        self.expected_count = len(items)\n",
    "        for item in items:\n",
    "            await ctx.send_message(item, target_id=\"sub_workflow\")\n",
    "    \n",
    "    @handler\n",
    "    async def collect_result(self, result: Result, ctx) -> None:\n",
    "        self.results.append(result)\n",
    "        \n",
    "        if len(self.results) == self.expected_count:\n",
    "            # All complete!\n",
    "            await ctx.add_event(AllTasksCompleted(self.results))\n",
    "```\n",
    "\n",
    "**Best Practices:**\n",
    "- Track expected result count\n",
    "- Use task IDs for correlation\n",
    "- Emit custom events for batch completion\n",
    "- Handle partial failures gracefully\n",
    "\n",
    "### 5. Custom Events\n",
    "\n",
    "```python\n",
    "class AllTasksCompleted(WorkflowEvent):\n",
    "    def __init__(self, results: list[Result]):\n",
    "        super().__init__(results)\n",
    "\n",
    "# In executor\n",
    "await ctx.add_event(AllTasksCompleted(self.results))\n",
    "```\n",
    "\n",
    "**Use Cases:**\n",
    "- Signaling batch completion\n",
    "- Triggering downstream processing\n",
    "- Workflow observability\n",
    "- State machine transitions\n",
    "\n",
    "### 6. Message Type Design\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class ProcessingRequest:\n",
    "    \"\"\"Input to sub-workflow.\"\"\"\n",
    "    text: str\n",
    "    task_id: str  # For result correlation\n",
    "\n",
    "@dataclass\n",
    "class ProcessingResult:\n",
    "    \"\"\"Output from sub-workflow.\"\"\"\n",
    "    task_id: str  # Matches request\n",
    "    data: Any\n",
    "```\n",
    "\n",
    "**Correlation Strategy:**\n",
    "- Include task_id in both request and result\n",
    "- Parent can match results to original requests\n",
    "- Essential for concurrent processing\n",
    "- Enables out-of-order result handling\n",
    "\n",
    "### 7. Sub-Workflow Isolation\n",
    "\n",
    "**Independence:**\n",
    "- Sub-workflows don't know they're nested\n",
    "- Can be tested standalone\n",
    "- Can be reused in different contexts\n",
    "- State is isolated from parent\n",
    "\n",
    "**Communication:**\n",
    "- Parent → Sub: Send message to WorkflowExecutor\n",
    "- Sub → Parent: yield_output() from sub-workflow\n",
    "- No direct state sharing\n",
    "- All communication via messages\n",
    "\n",
    "### 8. Production Patterns\n",
    "\n",
    "#### Error Handling\n",
    "```python\n",
    "@handler\n",
    "async def collect_result(self, result: Result, ctx) -> None:\n",
    "    if isinstance(result, ErrorResult):\n",
    "        self.errors.append(result)\n",
    "    else:\n",
    "        self.results.append(result)\n",
    "    \n",
    "    if len(self.results) + len(self.errors) == self.expected_count:\n",
    "        # Report completion with error summary\n",
    "        await ctx.add_event(BatchCompleted(\n",
    "            results=self.results,\n",
    "            errors=self.errors\n",
    "        ))\n",
    "```\n",
    "\n",
    "#### Timeout Handling\n",
    "```python\n",
    "parent = (\n",
    "    WorkflowBuilder()\n",
    "    .set_start_executor(orchestrator)\n",
    "    .add_edge(orchestrator, workflow_executor)\n",
    "    .with_timeout(30)  # Sub-workflows must complete within 30s\n",
    "    .build()\n",
    ")\n",
    "```\n",
    "\n",
    "#### Resource Management\n",
    "```python\n",
    "# Limit concurrent sub-workflows\n",
    "@handler\n",
    "async def start(self, items: list, ctx) -> None:\n",
    "    batch_size = 10\n",
    "    for i in range(0, len(items), batch_size):\n",
    "        batch = items[i:i+batch_size]\n",
    "        for item in batch:\n",
    "            await ctx.send_message(item, target_id=\"sub_workflow\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}