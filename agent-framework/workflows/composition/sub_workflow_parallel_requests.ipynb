{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09319f32",
   "metadata": {},
   "source": [
    "# Sub-Workflow Parallel Request Handling\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates **specialized parallel interception** - showing how multiple parent executors can handle different request types from the same sub-workflow using typed handlers.\n",
    "\n",
    "### Resource Allocation System:\n",
    "\n",
    "```\n",
    "Parent Workflow (Two Specialized Interceptors):\n",
    "  \n",
    "  Coordinator (start)\n",
    "      |\n",
    "      | Mixed request list [ResourceRequest, PolicyCheckRequest]\n",
    "      v\n",
    "  [ Sub-Workflow: WorkflowExecutor(ResourceRequester) ]\n",
    "      |\n",
    "      | Emits different RequestInfoMessage types:\n",
    "      |   - ResourceRequest (cpu, memory, disk)\n",
    "      |   - PolicyCheckRequest (quota, compliance, security)\n",
    "      v\n",
    "  Parent routes by type:\n",
    "      |\n",
    "      |-- ResourceRequest → ResourceCache.handle_resource_request()\n",
    "      |   |\n",
    "      |   |-- Cache hit → Send RequestResponse(source=\"cache\")\n",
    "      |   |-- Cache miss → Forward to external\n",
    "      |\n",
    "      |-- PolicyCheckRequest → PolicyEngine.handle_policy_request()\n",
    "          |\n",
    "          |-- Within quota → Send RequestResponse(approved=True)\n",
    "          |-- Exceeds quota → Forward to external\n",
    "```\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "1. **Type-Based Routing**: Different executors handle different message types\n",
    "2. **Specialized Interceptors**: ResourceCache vs. PolicyEngine\n",
    "3. **Parallel Processing**: Multiple request types processed concurrently\n",
    "4. **Automatic Filtering**: Handlers only receive matching types\n",
    "5. **Fallback Forwarding**: Unhandled requests go to external services\n",
    "6. **Result Collection**: Both interceptors collect their results\n",
    "\n",
    "### What You Learn:\n",
    "\n",
    "- Create multiple RequestInfoMessage subclasses\n",
    "- Build specialized interceptor executors\n",
    "- Use type-based handler routing\n",
    "- Handle mixed request types from one sub-workflow\n",
    "- Implement cache and policy layers\n",
    "- Coordinate multiple interception strategies\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Agent Framework installed: `pip install agent-framework`\n",
    "- No external services required (simulated via RequestInfoExecutor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3438b884",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6dea9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from dataclasses import dataclass\n",
    "from typing import Any\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from agent_framework import (\n",
    "    Executor,\n",
    "    RequestInfoExecutor,\n",
    "    RequestInfoMessage,\n",
    "    RequestResponse,\n",
    "    WorkflowBuilder,\n",
    "    WorkflowContext,\n",
    "    WorkflowExecutor,\n",
    "    handler,\n",
    ")\n",
    "from typing_extensions import Never\n",
    "# Load environment variables from .env file\n",
    "load_dotenv('../../.env')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1a683e",
   "metadata": {},
   "source": [
    "## Define Domain-Specific Request Types\n",
    "\n",
    "### Two Request Families:\n",
    "\n",
    "1. **ResourceRequest**: Computing resources (CPU, memory, disk)\n",
    "2. **PolicyCheckRequest**: Policy validation (quota, compliance, security)\n",
    "\n",
    "Each type routes to different interceptors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a523ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ResourceRequest(RequestInfoMessage):\n",
    "    \"\"\"Request for computing resources.\"\"\"\n",
    "    resource_type: str = \"cpu\"  # cpu, memory, disk, etc.\n",
    "    amount: int = 1\n",
    "    priority: str = \"normal\"  # low, normal, high\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PolicyCheckRequest(RequestInfoMessage):\n",
    "    \"\"\"Request to check resource allocation policy.\"\"\"\n",
    "    resource_type: str = \"\"\n",
    "    amount: int = 0\n",
    "    policy_type: str = \"quota\"  # quota, compliance, security\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ResourceResponse:\n",
    "    \"\"\"Response with allocated resources.\"\"\"\n",
    "    resource_type: str\n",
    "    allocated: int\n",
    "    source: str  # Which system provided the resources\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PolicyResponse:\n",
    "    \"\"\"Response from policy check.\"\"\"\n",
    "    approved: bool\n",
    "    reason: str\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RequestFinished:\n",
    "    \"\"\"Signals sub-workflow completion.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "print(\"✓ Message types defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc7684a",
   "metadata": {},
   "source": [
    "## Create Sub-Workflow Executor\n",
    "\n",
    "### ResourceRequester\n",
    "\n",
    "**Demonstrates:**\n",
    "- Processing mixed request types\n",
    "- Emitting different RequestInfoMessage subclasses\n",
    "- Handling typed responses (ResourceResponse, PolicyResponse)\n",
    "- Request counting for completion tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebcf72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResourceRequester(Executor):\n",
    "    \"\"\"Simple executor that requests resources and checks policies.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(id=\"resource_requester\")\n",
    "        self._request_count = 0\n",
    "\n",
    "    @handler\n",
    "    async def request_resources(\n",
    "        self,\n",
    "        requests: list[dict[str, Any]],\n",
    "        ctx: WorkflowContext[ResourceRequest | PolicyCheckRequest],\n",
    "    ) -> None:\n",
    "        \"\"\"Process a list of resource requests.\"\"\"\n",
    "        print(f\"🏭 Sub-workflow processing {len(requests)} requests\")\n",
    "        self._request_count += len(requests)\n",
    "\n",
    "        for req_data in requests:\n",
    "            req_type = req_data.get(\"request_type\", \"resource\")\n",
    "\n",
    "            request: ResourceRequest | PolicyCheckRequest\n",
    "            if req_type == \"resource\":\n",
    "                print(f\"  📦 Requesting resource: {req_data.get('type', 'cpu')} x{req_data.get('amount', 1)}\")\n",
    "                request = ResourceRequest(\n",
    "                    resource_type=req_data.get(\"type\", \"cpu\"),\n",
    "                    amount=req_data.get(\"amount\", 1),\n",
    "                    priority=req_data.get(\"priority\", \"normal\"),\n",
    "                )\n",
    "                # Send to parent workflow for interception - not to target_id\n",
    "                await ctx.send_message(request)\n",
    "            elif req_type == \"policy\":\n",
    "                print(\n",
    "                    f\"  🛡️  Checking policy: {req_data.get('type', 'cpu')} x{req_data.get('amount', 1)} \"\n",
    "                    f\"({req_data.get('policy_type', 'quota')})\"\n",
    "                )\n",
    "                request = PolicyCheckRequest(\n",
    "                    resource_type=req_data.get(\"type\", \"cpu\"),\n",
    "                    amount=req_data.get(\"amount\", 1),\n",
    "                    policy_type=req_data.get(\"policy_type\", \"quota\"),\n",
    "                )\n",
    "                # Send to parent workflow for interception - not to target_id\n",
    "                await ctx.send_message(request)\n",
    "\n",
    "    @handler\n",
    "    async def handle_resource_response(\n",
    "        self,\n",
    "        response: RequestResponse[ResourceRequest, ResourceResponse],\n",
    "        ctx: WorkflowContext[Never, RequestFinished],\n",
    "    ) -> None:\n",
    "        \"\"\"Handle resource allocation response.\"\"\"\n",
    "        if response.data:\n",
    "            source_icon = \"🏪\" if response.data.source == \"cache\" else \"🌐\"\n",
    "            print(\n",
    "                f\"📦 {source_icon} Sub-workflow received: {response.data.allocated} {response.data.resource_type} \"\n",
    "                f\"from {response.data.source}\"\n",
    "            )\n",
    "            if self._collect_results():\n",
    "                # Yield completion result to the parent workflow\n",
    "                await ctx.yield_output(RequestFinished())\n",
    "\n",
    "    @handler\n",
    "    async def handle_policy_response(\n",
    "        self,\n",
    "        response: RequestResponse[PolicyCheckRequest, PolicyResponse],\n",
    "        ctx: WorkflowContext[Never, RequestFinished],\n",
    "    ) -> None:\n",
    "        \"\"\"Handle policy check response.\"\"\"\n",
    "        if response.data:\n",
    "            status_icon = \"✅\" if response.data.approved else \"❌\"\n",
    "            print(\n",
    "                f\"🛡️  {status_icon} Sub-workflow received policy response: \"\n",
    "                f\"{response.data.approved} - {response.data.reason}\"\n",
    "            )\n",
    "            if self._collect_results():\n",
    "                # Yield completion result to the parent workflow\n",
    "                await ctx.yield_output(RequestFinished())\n",
    "\n",
    "    def _collect_results(self) -> bool:\n",
    "        \"\"\"Collect and summarize results.\"\"\"\n",
    "        self._request_count -= 1\n",
    "        print(f\"📊 Sub-workflow completed request ({self._request_count} remaining)\")\n",
    "        return self._request_count == 0\n",
    "\n",
    "\n",
    "print(\"✓ ResourceRequester executor created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d6beab",
   "metadata": {},
   "source": [
    "## Create Specialized Interceptor 1: ResourceCache\n",
    "\n",
    "### ResourceCache\n",
    "\n",
    "**Demonstrates:**\n",
    "- Typed handler for ResourceRequest (ONLY)\n",
    "- Cache hit/miss logic\n",
    "- Local response creation\n",
    "- External request forwarding\n",
    "- Result collection from external responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bce164",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResourceCache(Executor):\n",
    "    \"\"\"Interceptor that handles RESOURCE requests from cache using typed routing.\"\"\"\n",
    "\n",
    "    # Use class attributes to avoid Pydantic assignment restrictions\n",
    "    cache: dict[str, int] = {\"cpu\": 10, \"memory\": 50, \"disk\": 100}\n",
    "    results: list[ResourceResponse] = []\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(id=\"resource_cache\")\n",
    "\n",
    "    @handler\n",
    "    async def handle_resource_request(\n",
    "        self, \n",
    "        request: ResourceRequest, \n",
    "        ctx: WorkflowContext[RequestResponse[ResourceRequest, Any] | ResourceRequest]\n",
    "    ) -> None:\n",
    "        \"\"\"Handle RESOURCE requests from sub-workflows and check cache first.\"\"\"\n",
    "        resource_request = request\n",
    "        print(f\"🏪 CACHE interceptor checking: {resource_request.amount} {resource_request.resource_type}\")\n",
    "\n",
    "        available = self.cache.get(resource_request.resource_type, 0)\n",
    "\n",
    "        if available >= resource_request.amount:\n",
    "            # We can satisfy from cache\n",
    "            self.cache[resource_request.resource_type] -= resource_request.amount\n",
    "            response_data = ResourceResponse(\n",
    "                resource_type=resource_request.resource_type, \n",
    "                allocated=resource_request.amount, \n",
    "                source=\"cache\"\n",
    "            )\n",
    "            print(f\"  ✅ Cache satisfied: {resource_request.amount} {resource_request.resource_type}\")\n",
    "            self.results.append(response_data)\n",
    "\n",
    "            # Send response back to sub-workflow\n",
    "            response = RequestResponse(\n",
    "                data=response_data, \n",
    "                original_request=request, \n",
    "                request_id=request.request_id\n",
    "            )\n",
    "            await ctx.send_message(response, target_id=request.source_executor_id)\n",
    "        else:\n",
    "            # Cache miss - forward to external\n",
    "            print(f\"  ❌ Cache miss: need {resource_request.amount}, have {available} {resource_request.resource_type}\")\n",
    "            await ctx.send_message(request)\n",
    "\n",
    "    @handler\n",
    "    async def collect_result(\n",
    "        self, \n",
    "        response: RequestResponse[ResourceRequest, ResourceResponse], \n",
    "        ctx: WorkflowContext\n",
    "    ) -> None:\n",
    "        \"\"\"Collect results from external requests that were forwarded.\"\"\"\n",
    "        if response.data and response.data.source != \"cache\":  # Don't double-count our own results\n",
    "            self.results.append(response.data)\n",
    "            print(\n",
    "                f\"🏪 🌐 Cache received external response: {response.data.allocated} {response.data.resource_type} \"\n",
    "                f\"from {response.data.source}\"\n",
    "            )\n",
    "\n",
    "\n",
    "print(\"✓ ResourceCache interceptor created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ad479d",
   "metadata": {},
   "source": [
    "## Create Specialized Interceptor 2: PolicyEngine\n",
    "\n",
    "### PolicyEngine\n",
    "\n",
    "**Demonstrates:**\n",
    "- Typed handler for PolicyCheckRequest (ONLY)\n",
    "- Quota validation logic\n",
    "- Approval/rejection decisions\n",
    "- Unknown policy type forwarding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ad1a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyEngine(Executor):\n",
    "    \"\"\"Interceptor that handles POLICY requests using typed routing.\"\"\"\n",
    "\n",
    "    # Use class attributes for simple sample state\n",
    "    quota: dict[str, int] = {\n",
    "        \"cpu\": 5,  # Only allow up to 5 CPU units\n",
    "        \"memory\": 20,  # Only allow up to 20 memory units\n",
    "        \"disk\": 1000,  # Liberal disk policy\n",
    "    }\n",
    "    results: list[PolicyResponse] = []\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(id=\"policy_engine\")\n",
    "\n",
    "    @handler\n",
    "    async def handle_policy_request(\n",
    "        self,\n",
    "        request: PolicyCheckRequest,\n",
    "        ctx: WorkflowContext[RequestResponse[PolicyCheckRequest, Any] | PolicyCheckRequest],\n",
    "    ) -> None:\n",
    "        \"\"\"Handle POLICY requests from sub-workflows and apply rules.\"\"\"\n",
    "        policy_request = request\n",
    "        print(\n",
    "            f\"🛡️  POLICY interceptor checking: {policy_request.amount} {policy_request.resource_type}, \"\n",
    "            f\"policy={policy_request.policy_type}\"\n",
    "        )\n",
    "\n",
    "        quota_limit = self.quota.get(policy_request.resource_type, 0)\n",
    "\n",
    "        if policy_request.policy_type == \"quota\":\n",
    "            if policy_request.amount <= quota_limit:\n",
    "                response_data = PolicyResponse(\n",
    "                    approved=True, \n",
    "                    reason=f\"Within quota ({quota_limit})\"\n",
    "                )\n",
    "                print(f\"  ✅ Policy approved: {policy_request.amount} <= {quota_limit}\")\n",
    "                self.results.append(response_data)\n",
    "\n",
    "                # Send response back to sub-workflow\n",
    "                response = RequestResponse(\n",
    "                    data=response_data, \n",
    "                    original_request=request, \n",
    "                    request_id=request.request_id\n",
    "                )\n",
    "                await ctx.send_message(response, target_id=request.source_executor_id)\n",
    "                return\n",
    "\n",
    "            # Exceeds quota - forward to external for review\n",
    "            print(f\"  ❌ Policy exceeds quota: {policy_request.amount} > {quota_limit}, forwarding to external\")\n",
    "            await ctx.send_message(request)\n",
    "            return\n",
    "\n",
    "        # Unknown policy type - forward to external\n",
    "        print(f\"  ❓ Unknown policy type: {policy_request.policy_type}, forwarding\")\n",
    "        await ctx.send_message(request)\n",
    "\n",
    "    @handler\n",
    "    async def collect_policy_result(\n",
    "        self, \n",
    "        response: RequestResponse[PolicyCheckRequest, PolicyResponse], \n",
    "        ctx: WorkflowContext\n",
    "    ) -> None:\n",
    "        \"\"\"Collect policy results from external requests that were forwarded.\"\"\"\n",
    "        if response.data:\n",
    "            self.results.append(response.data)\n",
    "            print(f\"🛡️  🌐 Policy received external response: {response.data.approved} - {response.data.reason}\")\n",
    "\n",
    "\n",
    "print(\"✓ PolicyEngine interceptor created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983a1995",
   "metadata": {},
   "source": [
    "## Create Coordinator Executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dba205",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Coordinator(Executor):\n",
    "    \"\"\"Coordinates the workflow execution.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(id=\"coordinator\")\n",
    "\n",
    "    @handler\n",
    "    async def start(\n",
    "        self, \n",
    "        requests: list[dict[str, Any]], \n",
    "        ctx: WorkflowContext[list[dict[str, Any]]]\n",
    "    ) -> None:\n",
    "        \"\"\"Start the resource allocation process.\"\"\"\n",
    "        await ctx.send_message(requests, target_id=\"resource_workflow\")\n",
    "\n",
    "    @handler\n",
    "    async def handle_completion(\n",
    "        self, \n",
    "        completion: RequestFinished, \n",
    "        ctx: WorkflowContext\n",
    "    ) -> None:\n",
    "        \"\"\"Handle sub-workflow completion (from yielded output).\"\"\"\n",
    "        print(\"🎯 Main workflow received completion.\")\n",
    "\n",
    "\n",
    "print(\"✓ Coordinator executor created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa03c90",
   "metadata": {},
   "source": [
    "## Build Workflows\n",
    "\n",
    "### Sub-Workflow Graph:\n",
    "\n",
    "```\n",
    "ResourceRequester (start)\n",
    "    ↓\n",
    "RequestInfoExecutor (\"sub_request_info\")\n",
    "    ↓\n",
    "ResourceRequester (handle responses)\n",
    "```\n",
    "\n",
    "### Parent Workflow Graph (Type-Based Routing):\n",
    "\n",
    "```\n",
    "Coordinator (start)\n",
    "    ↓\n",
    "WorkflowExecutor (sub-workflow)\n",
    "    ↓ (ResourceRequest)\n",
    "ResourceCache.handle_resource_request()\n",
    "    ↓ (PolicyCheckRequest)\n",
    "PolicyEngine.handle_policy_request()\n",
    "    ↓ (RequestResponse)\n",
    "Back to WorkflowExecutor\n",
    "    ↓ (Forwarded requests)\n",
    "RequestInfoExecutor (\"main_request_info\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9583f88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🚀 Starting Sub-Workflow Parallel Request Interception Demo...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create the sub-workflow\n",
    "resource_requester = ResourceRequester()\n",
    "sub_request_info = RequestInfoExecutor(id=\"sub_request_info\")\n",
    "\n",
    "sub_workflow = (\n",
    "    WorkflowBuilder()\n",
    "    .set_start_executor(resource_requester)\n",
    "    .add_edge(resource_requester, sub_request_info)\n",
    "    .add_edge(sub_request_info, resource_requester)\n",
    "    .build()\n",
    ")\n",
    "\n",
    "print(\"✓ Sub-workflow created\")\n",
    "\n",
    "# Create parent workflow with PROPER interceptor pattern\n",
    "cache = ResourceCache()  # Intercepts ResourceRequest\n",
    "policy = PolicyEngine()  # Intercepts PolicyCheckRequest (different type!)\n",
    "workflow_executor = WorkflowExecutor(sub_workflow, id=\"resource_workflow\")\n",
    "main_request_info = RequestInfoExecutor(id=\"main_request_info\")\n",
    "\n",
    "# Create a simple coordinator that starts the process\n",
    "coordinator = Coordinator()\n",
    "\n",
    "# TYPED ROUTING: Each executor handles specific typed RequestInfoMessage messages\n",
    "main_workflow = (\n",
    "    WorkflowBuilder()\n",
    "    .set_start_executor(coordinator)\n",
    "    .add_edge(coordinator, workflow_executor)  # Start sub-workflow\n",
    "    .add_edge(workflow_executor, coordinator)  # Sub-workflow completion back to coordinator\n",
    "    .add_edge(workflow_executor, cache)  # WorkflowExecutor sends ResourceRequest to cache\n",
    "    .add_edge(workflow_executor, policy)  # WorkflowExecutor sends PolicyCheckRequest to policy\n",
    "    .add_edge(cache, workflow_executor)  # Cache sends RequestResponse back\n",
    "    .add_edge(policy, workflow_executor)  # Policy sends RequestResponse back\n",
    "    .add_edge(cache, main_request_info)  # Cache forwards ResourceRequest to external\n",
    "    .add_edge(policy, main_request_info)  # Policy forwards PolicyCheckRequest to external\n",
    "    .add_edge(main_request_info, workflow_executor)  # External responses back to sub-workflow\n",
    "    .build()\n",
    ")\n",
    "\n",
    "print(\"✓ Parent workflow created with specialized interceptors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970d34d7",
   "metadata": {},
   "source": [
    "## Prepare Test Data\n",
    "\n",
    "Testing with 7 mixed requests:\n",
    "1. **Resource: cpu x2** - Cache hit (10 available)\n",
    "2. **Policy: cpu x3, quota** - Policy hit (limit 5)\n",
    "3. **Resource: memory x15** - Cache hit (50 available)\n",
    "4. **Policy: memory x100, quota** - Policy miss (limit 20) → External\n",
    "5. **Resource: gpu x1** - Cache miss (not in cache) → External\n",
    "6. **Policy: disk x500, quota** - Policy hit (limit 1000)\n",
    "7. **Policy: cpu x1, security** - Unknown policy type → External"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7d371b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_requests = [\n",
    "    {\"request_type\": \"resource\", \"type\": \"cpu\", \"amount\": 2, \"priority\": \"normal\"},  # Cache hit\n",
    "    {\"request_type\": \"policy\", \"type\": \"cpu\", \"amount\": 3, \"policy_type\": \"quota\"},  # Policy hit\n",
    "    {\"request_type\": \"resource\", \"type\": \"memory\", \"amount\": 15, \"priority\": \"normal\"},  # Cache hit\n",
    "    {\"request_type\": \"policy\", \"type\": \"memory\", \"amount\": 100, \"policy_type\": \"quota\"},  # Policy miss → external\n",
    "    {\"request_type\": \"resource\", \"type\": \"gpu\", \"amount\": 1, \"priority\": \"high\"},  # Cache miss → external\n",
    "    {\"request_type\": \"policy\", \"type\": \"disk\", \"amount\": 500, \"policy_type\": \"quota\"},  # Policy hit\n",
    "    {\"request_type\": \"policy\", \"type\": \"cpu\", \"amount\": 1, \"policy_type\": \"security\"},  # Unknown policy → external\n",
    "]\n",
    "\n",
    "print(f\"\\n🧪 Testing with {len(test_requests)} mixed requests:\")\n",
    "for i, req in enumerate(test_requests, 1):\n",
    "    req_icon = \"📦\" if req[\"request_type\"] == \"resource\" else \"🛡️\"\n",
    "    print(\n",
    "        f\"  {i}. {req_icon} {req['type']} x{req['amount']} \"\n",
    "        f\"({req.get('priority', req.get('policy_type', 'default'))})\"\n",
    "    )\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653e979f",
   "metadata": {},
   "source": [
    "## Run Workflow\n",
    "\n",
    "Watch as:\n",
    "- ResourceRequest messages → ResourceCache interceptor\n",
    "- PolicyCheckRequest messages → PolicyEngine interceptor\n",
    "- Each interceptor decides: handle locally or forward\n",
    "- Responses routed back to sub-workflow automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec5b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n🎬 Running workflow...\")\n",
    "events = await main_workflow.run(test_requests)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3fb340",
   "metadata": {},
   "source": [
    "## Handle External Requests\n",
    "\n",
    "Requests that couldn't be handled by either interceptor are collected and simulated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07c104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_events = events.get_request_info_events()\n",
    "\n",
    "if request_events:\n",
    "    print(f\"\\n🌐 Handling {len(request_events)} external request(s)...\")\n",
    "\n",
    "    external_responses: dict[str, Any] = {}\n",
    "    for event in request_events:\n",
    "        if isinstance(event.data, ResourceRequest):\n",
    "            # Handle ResourceRequest - create ResourceResponse\n",
    "            resource_response = ResourceResponse(\n",
    "                resource_type=event.data.resource_type, \n",
    "                allocated=event.data.amount, \n",
    "                source=\"external_provider\"\n",
    "            )\n",
    "            external_responses[event.request_id] = resource_response\n",
    "            print(f\"  🏭 External provider: {resource_response.allocated} {resource_response.resource_type}\")\n",
    "        elif isinstance(event.data, PolicyCheckRequest):\n",
    "            # Handle PolicyCheckRequest - create PolicyResponse\n",
    "            policy_response = PolicyResponse(\n",
    "                approved=True, \n",
    "                reason=\"External policy service approved\"\n",
    "            )\n",
    "            external_responses[event.request_id] = policy_response\n",
    "            print(f\"  🔒 External policy: {'✅ APPROVED' if policy_response.approved else '❌ DENIED'}\")\n",
    "\n",
    "    await main_workflow.send_responses(external_responses)\n",
    "else:\n",
    "    print(\"\\n🎯 All requests were intercepted internally!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ef14df",
   "metadata": {},
   "source": [
    "## Display Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688bf12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"📊 RESULTS ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\n🏪 Cache Results ({len(cache.results)} handled):\")\n",
    "for result in cache.results:\n",
    "    print(f\"  ✅ {result.allocated} {result.resource_type} from {result.source}\")\n",
    "\n",
    "print(f\"\\n🛡️  Policy Results ({len(policy.results)} handled):\")\n",
    "for result in policy.results:\n",
    "    status_icon = \"✅\" if result.approved else \"❌\"\n",
    "    print(f\"  {status_icon} Approved: {result.approved} - {result.reason}\")\n",
    "\n",
    "print(\"\\n💾 Final Cache State:\")\n",
    "for resource, amount in cache.cache.items():\n",
    "    print(f\"  📦 {resource}: {amount} remaining\")\n",
    "\n",
    "print(\"\\n📈 Summary:\")\n",
    "print(f\"  🎯 Total requests: {len(test_requests)}\")\n",
    "print(f\"  🏪 Resource requests handled: {len(cache.results)}\")\n",
    "print(f\"  🛡️  Policy requests handled: {len(policy.results)}\")\n",
    "print(f\"  🌐 External requests: {len(request_events) if request_events else 0}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680f5420",
   "metadata": {},
   "source": [
    "## Expected Output Pattern\n",
    "\n",
    "```\n",
    "🚀 Starting Sub-Workflow Parallel Request Interception Demo...\n",
    "============================================================\n",
    "✓ Sub-workflow created\n",
    "✓ Parent workflow created with specialized interceptors\n",
    "\n",
    "🧪 Testing with 7 mixed requests:\n",
    "  1. 📦 cpu x2 (normal)\n",
    "  2. 🛡️ cpu x3 (quota)\n",
    "  3. 📦 memory x15 (normal)\n",
    "  4. 🛡️ memory x100 (quota)\n",
    "  5. 📦 gpu x1 (high)\n",
    "  6. 🛡️ disk x500 (quota)\n",
    "  7. 🛡️ cpu x1 (security)\n",
    "======================================================================\n",
    "\n",
    "🎬 Running workflow...\n",
    "🏭 Sub-workflow processing 7 requests\n",
    "  📦 Requesting resource: cpu x2\n",
    "  🛡️  Checking policy: cpu x3 (quota)\n",
    "  📦 Requesting resource: memory x15\n",
    "  🛡️  Checking policy: memory x100 (quota)\n",
    "  📦 Requesting resource: gpu x1\n",
    "  🛡️  Checking policy: disk x500 (quota)\n",
    "  🛡️  Checking policy: cpu x1 (security)\n",
    "🏪 CACHE interceptor checking: 2 cpu\n",
    "  ✅ Cache satisfied: 2 cpu\n",
    "📦 🏪 Sub-workflow received: 2 cpu from cache\n",
    "📊 Sub-workflow completed request (6 remaining)\n",
    "🛡️  POLICY interceptor checking: 3 cpu, policy=quota\n",
    "  ✅ Policy approved: 3 <= 5\n",
    "🛡️  ✅ Sub-workflow received policy response: True - Within quota (5)\n",
    "📊 Sub-workflow completed request (5 remaining)\n",
    "🏪 CACHE interceptor checking: 15 memory\n",
    "  ✅ Cache satisfied: 15 memory\n",
    "📦 🏪 Sub-workflow received: 15 memory from cache\n",
    "📊 Sub-workflow completed request (4 remaining)\n",
    "🛡️  POLICY interceptor checking: 100 memory, policy=quota\n",
    "  ❌ Policy exceeds quota: 100 > 20, forwarding to external\n",
    "🏪 CACHE interceptor checking: 1 gpu\n",
    "  ❌ Cache miss: need 1, have 0 gpu\n",
    "🛡️  POLICY interceptor checking: 500 disk, policy=quota\n",
    "  ✅ Policy approved: 500 <= 1000\n",
    "🛡️  ✅ Sub-workflow received policy response: True - Within quota (1000)\n",
    "📊 Sub-workflow completed request (3 remaining)\n",
    "🛡️  POLICY interceptor checking: 1 cpu, policy=security\n",
    "  ❓ Unknown policy type: security, forwarding\n",
    "\n",
    "🌐 Handling 3 external request(s)...\n",
    "  🏭 External provider: 1 gpu\n",
    "  🔒 External policy: ✅ APPROVED\n",
    "  🔒 External policy: ✅ APPROVED\n",
    "🏪 🌐 Cache received external response: 1 gpu from external_provider\n",
    "📦 🌐 Sub-workflow received: 1 gpu from external_provider\n",
    "📊 Sub-workflow completed request (2 remaining)\n",
    "🛡️  🌐 Policy received external response: True - External policy service approved\n",
    "🛡️  ✅ Sub-workflow received policy response: True - External policy service approved\n",
    "📊 Sub-workflow completed request (1 remaining)\n",
    "🛡️  🌐 Policy received external response: True - External policy service approved\n",
    "🛡️  ✅ Sub-workflow received policy response: True - External policy service approved\n",
    "📊 Sub-workflow completed request (0 remaining)\n",
    "🎯 Main workflow received completion.\n",
    "\n",
    "======================================================================\n",
    "📊 RESULTS ANALYSIS\n",
    "======================================================================\n",
    "\n",
    "🏪 Cache Results (3 handled):\n",
    "  ✅ 2 cpu from cache\n",
    "  ✅ 15 memory from cache\n",
    "  ✅ 1 gpu from external_provider\n",
    "\n",
    "🛡️  Policy Results (4 handled):\n",
    "  ✅ Approved: True - Within quota (5)\n",
    "  ✅ Approved: True - Within quota (1000)\n",
    "  ✅ Approved: True - External policy service approved\n",
    "  ✅ Approved: True - External policy service approved\n",
    "\n",
    "💾 Final Cache State:\n",
    "  📦 cpu: 8 remaining\n",
    "  📦 memory: 35 remaining\n",
    "  📦 disk: 100 remaining\n",
    "\n",
    "📈 Summary:\n",
    "  🎯 Total requests: 7\n",
    "  🏪 Resource requests handled: 3\n",
    "  🛡️  Policy requests handled: 4\n",
    "  🌐 External requests: 3\n",
    "\n",
    "======================================================================\n",
    "```\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "### 1. Type-Based Routing\n",
    "\n",
    "```python\n",
    "# Each executor handles specific message type\n",
    "class ResourceCache(Executor):\n",
    "    @handler\n",
    "    async def handle_resource_request(\n",
    "        self,\n",
    "        request: ResourceRequest,  # ONLY ResourceRequest\n",
    "        ctx: WorkflowContext[...]\n",
    "    ) -> None:\n",
    "        ...\n",
    "\n",
    "class PolicyEngine(Executor):\n",
    "    @handler\n",
    "    async def handle_policy_request(\n",
    "        self,\n",
    "        request: PolicyCheckRequest,  # ONLY PolicyCheckRequest\n",
    "        ctx: WorkflowContext[...]\n",
    "    ) -> None:\n",
    "        ...\n",
    "```\n",
    "\n",
    "**Framework Behavior:**\n",
    "- Inspects message type at runtime\n",
    "- Routes to matching handler signature\n",
    "- Both executors receive messages from same source\n",
    "- No manual routing code needed\n",
    "\n",
    "### 2. Multiple Interceptor Pattern\n",
    "\n",
    "```python\n",
    "# In workflow graph\n",
    "builder = (\n",
    "    WorkflowBuilder()\n",
    "    .add_edge(workflow_executor, cache)    # ResourceRequest → cache\n",
    "    .add_edge(workflow_executor, policy)   # PolicyCheckRequest → policy\n",
    "    .add_edge(cache, workflow_executor)    # Responses back\n",
    "    .add_edge(policy, workflow_executor)   # Responses back\n",
    ")\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "- Separation of concerns\n",
    "- Independent testing\n",
    "- Easy to add new interceptors\n",
    "- Clear responsibility boundaries\n",
    "\n",
    "### 3. Specialized Interception Logic\n",
    "\n",
    "#### Resource Cache Pattern\n",
    "```python\n",
    "if available >= requested:\n",
    "    # Handle locally from cache\n",
    "    self.cache[resource] -= requested\n",
    "    response = RequestResponse(data=result, ...)\n",
    "    await ctx.send_message(response, target_id=source_executor_id)\n",
    "else:\n",
    "    # Forward to external provider\n",
    "    await ctx.send_message(request)\n",
    "```\n",
    "\n",
    "#### Policy Engine Pattern\n",
    "```python\n",
    "if policy_type == \"quota\":\n",
    "    if amount <= quota_limit:\n",
    "        # Approve locally\n",
    "        response = RequestResponse(data=PolicyResponse(approved=True), ...)\n",
    "        await ctx.send_message(response, target_id=source_executor_id)\n",
    "    else:\n",
    "        # Forward for manual review\n",
    "        await ctx.send_message(request)\n",
    "else:\n",
    "    # Unknown policy - forward to specialized service\n",
    "    await ctx.send_message(request)\n",
    "```\n",
    "\n",
    "### 4. Result Collection Patterns\n",
    "\n",
    "```python\n",
    "class Interceptor(Executor):\n",
    "    results: list[Response] = []\n",
    "    \n",
    "    @handler\n",
    "    async def handle_request(self, request: Request, ctx) -> None:\n",
    "        if can_handle_locally:\n",
    "            result = process(request)\n",
    "            self.results.append(result)  # Collect local result\n",
    "            ...\n",
    "    \n",
    "    @handler\n",
    "    async def collect_external_result(self, response: RequestResponse, ctx) -> None:\n",
    "        # Collect results from forwarded requests\n",
    "        if response.data and is_external(response.data):\n",
    "            self.results.append(response.data)\n",
    "```\n",
    "\n",
    "### 5. Concurrent Request Handling\n",
    "\n",
    "**Sub-workflow perspective:**\n",
    "```python\n",
    "# Send 7 requests concurrently - no await between sends\n",
    "for request_data in requests:\n",
    "    request = create_request(request_data)\n",
    "    await ctx.send_message(request)  # Non-blocking\n",
    "```\n",
    "\n",
    "**Interceptor perspective:**\n",
    "```python\n",
    "# Each interceptor handles its type independently\n",
    "# No coordination needed between ResourceCache and PolicyEngine\n",
    "# Framework ensures correct correlation via request_id\n",
    "```\n",
    "\n",
    "### 6. Production Patterns\n",
    "\n",
    "#### Multi-Tier Cache\n",
    "```python\n",
    "class L1Cache(Executor):\n",
    "    @handler\n",
    "    async def check_l1(self, request: DataRequest, ctx) -> None:\n",
    "        if request.key in self.memory_cache:\n",
    "            # L1 hit - fastest\n",
    "            ...\n",
    "        else:\n",
    "            # Forward to L2\n",
    "            await ctx.send_message(request)\n",
    "\n",
    "class L2Cache(Executor):\n",
    "    @handler\n",
    "    async def check_l2(self, request: DataRequest, ctx) -> None:\n",
    "        if request.key in self.disk_cache:\n",
    "            # L2 hit - slower but available\n",
    "            ...\n",
    "        else:\n",
    "            # Forward to external\n",
    "            await ctx.send_message(request)\n",
    "```\n",
    "\n",
    "#### Priority-Based Routing\n",
    "```python\n",
    "class PriorityRouter(Executor):\n",
    "    @handler\n",
    "    async def route_request(self, request: ResourceRequest, ctx) -> None:\n",
    "        if request.priority == \"high\":\n",
    "            # High priority - allocate immediately\n",
    "            response = RequestResponse(data=allocate_premium(request), ...)\n",
    "            await ctx.send_message(response, target_id=request.source_executor_id)\n",
    "        elif request.priority == \"normal\":\n",
    "            # Normal - check availability\n",
    "            await ctx.send_message(request)  # Forward to cache\n",
    "        else:\n",
    "            # Low priority - queue for batch processing\n",
    "            self.queue.append(request)\n",
    "```\n",
    "\n",
    "#### A/B Testing\n",
    "```python\n",
    "class ABTestInterceptor(Executor):\n",
    "    @handler\n",
    "    async def ab_test(self, request: APIRequest, ctx) -> None:\n",
    "        if hash(request.user_id) % 2 == 0:\n",
    "            # Group A - use optimized path\n",
    "            result = optimized_handler(request)\n",
    "            response = RequestResponse(data=result, ...)\n",
    "            await ctx.send_message(response, target_id=request.source_executor_id)\n",
    "        else:\n",
    "            # Group B - use standard path\n",
    "            await ctx.send_message(request)\n",
    "```\n",
    "\n",
    "### 7. Error Handling in Interceptors\n",
    "\n",
    "```python\n",
    "@handler\n",
    "async def handle_request(self, request: Request, ctx) -> None:\n",
    "    try:\n",
    "        if can_handle:\n",
    "            result = process(request)\n",
    "            response = RequestResponse(data=result, ...)\n",
    "            await ctx.send_message(response, target_id=request.source_executor_id)\n",
    "        else:\n",
    "            await ctx.send_message(request)\n",
    "    except Exception as e:\n",
    "        # Send error response instead of crashing\n",
    "        error_response = RequestResponse(\n",
    "            data=None,\n",
    "            error=str(e),\n",
    "            original_request=request,\n",
    "            request_id=request.request_id\n",
    "        )\n",
    "        await ctx.send_message(error_response, target_id=request.source_executor_id)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}