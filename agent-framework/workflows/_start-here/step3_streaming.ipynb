{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "079901dd",
   "metadata": {},
   "source": [
    "# Step 3: Agents in a Workflow with Streaming\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates **streaming workflow execution**, allowing you to observe events as they occur in real-time. We'll build a two-agent workflow with:\n",
    "1. **Writer Agent** - Generates content\n",
    "2. **Reviewer Agent** - Reviews and finalizes the result\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "- **Streaming Execution**: Using `workflow.run_stream()` to observe events in real-time\n",
    "- **Custom Executor Classes**: Creating reusable executor components with embedded agents\n",
    "- **Event Types**: Understanding different workflow events (status, output, errors)\n",
    "- **Event Origin**: Distinguishing runner-generated vs executor-generated events\n",
    "- **Typed Contexts**: Using `WorkflowContext[T_Out, T_W_Out]` for type safety\n",
    "\n",
    "### Prerequisites:\n",
    "\n",
    "- ✅ Azure OpenAI configured with required environment variables\n",
    "- ✅ Azure CLI authentication (`az login` completed)\n",
    "- ✅ Completion of Step 1 and Step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfd5418",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9112d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "from agent_framework import (\n",
    "    ChatAgent,\n",
    "    ChatMessage,\n",
    "    Executor,\n",
    "    ExecutorFailedEvent,\n",
    "    WorkflowBuilder,\n",
    "    WorkflowContext,\n",
    "    WorkflowFailedEvent,\n",
    "    WorkflowRunState,\n",
    "    WorkflowStatusEvent,\n",
    "    handler,\n",
    ")\n",
    "from agent_framework._workflows._events import WorkflowOutputEvent\n",
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "from azure.identity import AzureCliCredential\n",
    "from typing_extensions import Never\n",
    "from pathlib import Path\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "notebook_path = Path().absolute()\n",
    "parent_dir = notebook_path.parent\n",
    "load_dotenv('../../.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3c09d0",
   "metadata": {},
   "source": [
    "## Create Azure OpenAI Chat Client\n",
    "\n",
    "We'll use **Azure OpenAI** with `AzureCliCredential` for authentication.\n",
    "\n",
    "### Environment Variables Required:\n",
    "- **AZURE_OPENAI_ENDPOINT**: Your Azure OpenAI endpoint URL\n",
    "- **AZURE_OPENAI_CHAT_DEPLOYMENT_NAME**: Your model deployment name (e.g., \"gpt-4o\")\n",
    "\n",
    "These should be set in the `.env` file located at `python/samples/getting_started/.env`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55602bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify environment variables are loaded\n",
    "print(\"🔍 Checking Azure OpenAI environment variables...\")\n",
    "print(f\"AZURE_OPENAI_ENDPOINT: {os.getenv('AZURE_OPENAI_ENDPOINT', 'Not set')}\")\n",
    "print(f\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME: {os.getenv('AZURE_OPENAI_CHAT_DEPLOYMENT_NAME', 'Not set')}\")\n",
    "\n",
    "# Create the Azure OpenAI chat client\n",
    "endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "deployment_name = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "\n",
    "if not endpoint:\n",
    "    raise ValueError(\"❌ Azure OpenAI endpoint not found. Please set AZURE_OPENAI_ENDPOINT in your .env file\")\n",
    "\n",
    "if not deployment_name:\n",
    "    raise ValueError(\"❌ Azure OpenAI deployment name not found. Please set AZURE_OPENAI_CHAT_DEPLOYMENT_NAME in your .env file\")\n",
    "\n",
    "print(f\"🔧 Using Azure OpenAI Endpoint: {endpoint}\")\n",
    "print(f\"🔧 Using Deployment: {deployment_name}\")\n",
    "\n",
    "# Create the Azure OpenAI chat client\n",
    "chat_client = AzureOpenAIChatClient(\n",
    "    deployment_name=deployment_name,\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureCliCredential()\n",
    ")\n",
    "\n",
    "print(\"✅ Azure OpenAI Chat Client created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bdff92",
   "metadata": {},
   "source": [
    "## Define the Writer Executor\n",
    "\n",
    "### Custom Executor Pattern\n",
    "\n",
    "This class demonstrates:\n",
    "- Attaching a `ChatAgent` to an `Executor` for workflow participation\n",
    "- Using `@handler` method with typed input and output\n",
    "- Forwarding typed output via `ctx.send_message()`\n",
    "\n",
    "### Handler Contract:\n",
    "- **Input**: `ChatMessage` (inbound user message)\n",
    "- **Context**: `WorkflowContext[list[ChatMessage]]` (expects list of messages downstream)\n",
    "\n",
    "### Pattern:\n",
    "1. Seed conversation with inbound message\n",
    "2. Run attached agent to produce assistant messages\n",
    "3. Forward cumulative messages to next executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e4a16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Writer(Executor):\n",
    "    \"\"\"Custom executor that owns a domain-specific agent for content generation.\"\"\"\n",
    "\n",
    "    agent: ChatAgent\n",
    "\n",
    "    def __init__(self, chat_client: AzureOpenAIChatClient, id: str = \"writer\"):\n",
    "        # Create a domain-specific agent using your configured AzureOpenAIChatClient\n",
    "        self.agent = chat_client.create_agent(\n",
    "            instructions=(\n",
    "                \"You are an excellent content writer. You create new content and edit contents based on the feedback.\"\n",
    "            ),\n",
    "        )\n",
    "        # Associate this agent with the executor node\n",
    "        super().__init__(id=id)\n",
    "\n",
    "    @handler\n",
    "    async def handle(self, message: ChatMessage, ctx: WorkflowContext[list[ChatMessage]]) -> None:\n",
    "        \"\"\"Generate content and forward the updated conversation.\n",
    "\n",
    "        Contract for this handler:\n",
    "        - message is the inbound user ChatMessage\n",
    "        - ctx is a WorkflowContext that expects a list[ChatMessage] to be sent downstream\n",
    "        \"\"\"\n",
    "        # Start the conversation with the incoming user message\n",
    "        messages: list[ChatMessage] = [message]\n",
    "        \n",
    "        # Run the agent and extend the conversation with the agent's messages\n",
    "        response = await self.agent.run(messages)\n",
    "        messages.extend(response.messages)\n",
    "        \n",
    "        # Forward the accumulated messages to the next executor in the workflow\n",
    "        await ctx.send_message(messages)\n",
    "\n",
    "print(\"✅ Writer Executor class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f66246",
   "metadata": {},
   "source": [
    "## Define the Reviewer Executor\n",
    "\n",
    "### Terminal Node Pattern\n",
    "\n",
    "This executor demonstrates:\n",
    "- Consuming the full conversation transcript\n",
    "- Using `WorkflowContext[Never, str]` for terminal nodes\n",
    "  - `Never` = does not send messages to downstream nodes\n",
    "  - `str` = yields string as final workflow output\n",
    "- Completing the workflow with `ctx.yield_output()`\n",
    "\n",
    "### Handler Contract:\n",
    "- **Input**: `list[ChatMessage]` (full conversation history)\n",
    "- **Context**: `WorkflowContext[Never, str]` (terminal node yielding string output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882f725c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reviewer(Executor):\n",
    "    \"\"\"Custom executor that owns a review agent and completes the workflow.\"\"\"\n",
    "\n",
    "    agent: ChatAgent\n",
    "\n",
    "    def __init__(self, chat_client: AzureOpenAIChatClient, id: str = \"reviewer\"):\n",
    "        # Create a domain-specific agent that evaluates and refines content\n",
    "        self.agent = chat_client.create_agent(\n",
    "            instructions=(\n",
    "                \"You are an excellent content reviewer. You review the content and provide feedback to the writer.\"\n",
    "            ),\n",
    "        )\n",
    "        super().__init__(id=id)\n",
    "\n",
    "    @handler\n",
    "    async def handle(self, messages: list[ChatMessage], ctx: WorkflowContext[Never, str]) -> None:\n",
    "        \"\"\"Review the full conversation transcript and yield the final output.\n",
    "\n",
    "        This node consumes all messages so far. It uses its agent to produce the final text,\n",
    "        then yields the output. The workflow completes when it becomes idle.\n",
    "        \"\"\"\n",
    "        response = await self.agent.run(messages)\n",
    "        await ctx.yield_output(response.text)\n",
    "\n",
    "print(\"✅ Reviewer Executor class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab26313",
   "metadata": {},
   "source": [
    "## Create Executor Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8008dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the two agent-backed executors\n",
    "writer = Writer(chat_client)\n",
    "reviewer = Reviewer(chat_client)\n",
    "\n",
    "print(\"✅ Writer and Reviewer instances created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d70727c",
   "metadata": {},
   "source": [
    "## Build the Workflow\n",
    "\n",
    "### Workflow Structure:\n",
    "\n",
    "```\n",
    "Writer → Reviewer\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164a5d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the workflow using the fluent builder\n",
    "workflow = (\n",
    "    WorkflowBuilder()\n",
    "    .set_start_executor(writer)\n",
    "    .add_edge(writer, reviewer)\n",
    "    .build()\n",
    ")\n",
    "\n",
    "print(\"✅ Workflow built successfully!\")\n",
    "print(\"   Writer → Reviewer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4649f1e9",
   "metadata": {},
   "source": [
    "## Run the Workflow with Streaming\n",
    "\n",
    "### Streaming Events\n",
    "\n",
    "Using `workflow.run_stream()` provides real-time visibility into:\n",
    "- **WorkflowStatusEvent**: State changes (IN_PROGRESS, IDLE, etc.)\n",
    "- **WorkflowOutputEvent**: Final outputs from terminal nodes\n",
    "- **ExecutorInvokeEvent**: When executors are invoked\n",
    "- **ExecutorCompletedEvent**: When executors complete\n",
    "- **ExecutorFailedEvent**: Executor-level errors\n",
    "- **WorkflowFailedEvent**: Workflow-level failures\n",
    "\n",
    "### Event Origin\n",
    "\n",
    "Each event has an `origin` field:\n",
    "- **RUNNER**: Lifecycle events (state changes, invocations)\n",
    "- **EXECUTOR**: Data-plane events (outputs, errors)\n",
    "\n",
    "### Workflow States\n",
    "\n",
    "- `IN_PROGRESS` - Workflow is actively processing\n",
    "- `IN_PROGRESS_PENDING_REQUESTS` - Processing with external requests in flight\n",
    "- `IDLE` - No active work, workflow complete or waiting\n",
    "- `IDLE_WITH_PENDING_REQUESTS` - Waiting for user input or external data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b20ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User message\n",
    "user_message = \"Create a slogan for a new electric SUV that is affordable and fun to drive.\"\n",
    "\n",
    "print(f\"\\n📝 User Request: {user_message}\\n\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\n🔄 Streaming Events:\\n\")\n",
    "\n",
    "# Run the workflow with streaming to observe events as they occur\n",
    "async for event in workflow.run_stream(\n",
    "    ChatMessage(role=\"user\", text=user_message)\n",
    "):\n",
    "    if isinstance(event, WorkflowStatusEvent):\n",
    "        prefix = f\"State ({event.origin.value}): \"\n",
    "        if event.state == WorkflowRunState.IN_PROGRESS:\n",
    "            print(prefix + \"IN_PROGRESS\")\n",
    "        elif event.state == WorkflowRunState.IN_PROGRESS_PENDING_REQUESTS:\n",
    "            print(prefix + \"IN_PROGRESS_PENDING_REQUESTS (requests in flight)\")\n",
    "        elif event.state == WorkflowRunState.IDLE:\n",
    "            print(prefix + \"IDLE (no active work)\")\n",
    "        elif event.state == WorkflowRunState.IDLE_WITH_PENDING_REQUESTS:\n",
    "            print(prefix + \"IDLE_WITH_PENDING_REQUESTS (prompt user or UI now)\")\n",
    "        else:\n",
    "            print(prefix + str(event.state))\n",
    "    \n",
    "    elif isinstance(event, WorkflowOutputEvent):\n",
    "        print(f\"\\n📤 Workflow output ({event.origin.value}): {event.data}\")\n",
    "    \n",
    "    elif isinstance(event, ExecutorFailedEvent):\n",
    "        print(\n",
    "            f\"❌ Executor failed ({event.origin.value}): \"\n",
    "            f\"{event.executor_id} {event.details.error_type}: {event.details.message}\"\n",
    "        )\n",
    "    \n",
    "    elif isinstance(event, WorkflowFailedEvent):\n",
    "        details = event.details\n",
    "        print(f\"❌ Workflow failed ({event.origin.value}): {details.error_type}: {details.message}\")\n",
    "    \n",
    "    else:\n",
    "        print(f\"{event.__class__.__name__} ({event.origin.value}): {event}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"\\n✅ Workflow execution completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10da3659",
   "metadata": {},
   "source": [
    "## Expected Output\n",
    "\n",
    "### Sample Streaming Events:\n",
    "\n",
    "```\n",
    "State (RUNNER): IN_PROGRESS\n",
    "ExecutorInvokeEvent (RUNNER): ExecutorInvokeEvent(executor_id=writer)\n",
    "ExecutorCompletedEvent (RUNNER): ExecutorCompletedEvent(executor_id=writer)\n",
    "ExecutorInvokeEvent (RUNNER): ExecutorInvokeEvent(executor_id=reviewer)\n",
    "📤 Workflow output (EXECUTOR): Drive the Future. Affordable Adventure, Electrified.\n",
    "ExecutorCompletedEvent (RUNNER): ExecutorCompletedEvent(executor_id=reviewer)\n",
    "State (RUNNER): IDLE\n",
    "```\n",
    "\n",
    "### Event Flow Explanation:\n",
    "\n",
    "1. **IN_PROGRESS** - Workflow starts processing\n",
    "2. **ExecutorInvokeEvent (writer)** - Writer agent is invoked\n",
    "3. **ExecutorCompletedEvent (writer)** - Writer completes and forwards messages\n",
    "4. **ExecutorInvokeEvent (reviewer)** - Reviewer agent is invoked\n",
    "5. **WorkflowOutputEvent** - Reviewer yields final output\n",
    "6. **ExecutorCompletedEvent (reviewer)** - Reviewer completes\n",
    "7. **IDLE** - Workflow becomes idle and completes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ac15b0",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### Streaming vs Non-Streaming\n",
    "\n",
    "| Feature | `run()` (Non-Streaming) | `run_stream()` (Streaming) |\n",
    "|---------|------------------------|---------------------------|\n",
    "| **Execution** | Waits for completion | Real-time events |\n",
    "| **Return Type** | Event collection | Async iterator |\n",
    "| **User Experience** | Batch processing | Real-time feedback |\n",
    "| **Use Case** | Simple workflows | Interactive applications |\n",
    "| **Covered In** | Step 2 | Step 3 (this notebook) |\n",
    "\n",
    "### Custom Executor Pattern\n",
    "\n",
    "✅ **When to Use Custom Executors:**\n",
    "- Need to manage agent state\n",
    "- Require lifecycle hooks (initialization, cleanup)\n",
    "- Building reusable workflow components\n",
    "- Domain-specific agent configurations\n",
    "\n",
    "✅ **Handler Signature Pattern:**\n",
    "```python\n",
    "@handler\n",
    "async def handle(self, input: InputType, ctx: WorkflowContext[OutputType]) -> None:\n",
    "    # Process input\n",
    "    # Send to downstream nodes: await ctx.send_message(output)\n",
    "    # Or yield final output: await ctx.yield_output(result)\n",
    "```\n",
    "\n",
    "### Event Types and Origin\n",
    "\n",
    "**RUNNER Events (Lifecycle):**\n",
    "- `WorkflowStatusEvent` - State transitions\n",
    "- `ExecutorInvokeEvent` - Executor invocations\n",
    "- `ExecutorCompletedEvent` - Executor completions\n",
    "\n",
    "**EXECUTOR Events (Data-Plane):**\n",
    "- `WorkflowOutputEvent` - Final outputs\n",
    "- `ExecutorFailedEvent` - Executor errors\n",
    "\n",
    "### Message Flow Pattern\n",
    "\n",
    "```\n",
    "User Input (ChatMessage)\n",
    "    ↓\n",
    "Writer Handler\n",
    "    ├─ Creates conversation: [user_message]\n",
    "    ├─ Runs writer agent → adds assistant messages\n",
    "    └─ Forwards: ctx.send_message(all_messages)\n",
    "    ↓\n",
    "Reviewer Handler\n",
    "    ├─ Receives: list[ChatMessage]\n",
    "    ├─ Runs reviewer agent on full conversation\n",
    "    └─ Yields: ctx.yield_output(final_text)\n",
    "    ↓\n",
    "Workflow Output\n",
    "```\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "Explore advanced workflow patterns:\n",
    "- **Control Flow**: Conditional edges, loops, switch-case\n",
    "- **Parallelism**: Fan-out/fan-in, concurrent execution\n",
    "- **Orchestration**: Multi-agent coordination\n",
    "- **Human-in-the-Loop**: Interactive workflows with user approval"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}