{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58f8a826",
   "metadata": {},
   "source": [
    "# Tool-Enabled Agents with Human Feedback\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to build a sophisticated workflow that combines:\n",
    "- **Tool/function calling**: Agents that invoke Python functions to gather information\n",
    "- **Human-in-the-loop**: Pausing execution to collect human feedback\n",
    "- **Multi-agent coordination**: Writer agent → Human review → Editor agent\n",
    "\n",
    "The workflow creates marketing copy through a three-stage process:\n",
    "1. **Writer Agent**: Calls tools to gather product details and brand guidelines, then drafts initial copy\n",
    "2. **Human Reviewer**: Reviews the draft and provides feedback via `RequestInfoExecutor`\n",
    "3. **Final Editor Agent**: Incorporates human feedback to produce polished output\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "### Tool Calling\n",
    "- Attach Python functions to agents via the `tools` parameter\n",
    "- Use `ToolMode.REQUIRED_ANY` to force the agent to call tools before responding\n",
    "- Monitor tool calls and results via `FunctionCallContent` and `FunctionResultContent`\n",
    "\n",
    "### Human-in-the-Loop Pattern\n",
    "- `RequestInfoExecutor`: Built-in executor that pauses workflow for external input\n",
    "- `RequestInfoEvent`: Emitted when human input is needed\n",
    "- `RequestResponse`: Packages human feedback for re-injection into the workflow\n",
    "\n",
    "### Custom Coordinator Executor\n",
    "- `DraftFeedbackCoordinator`: Bridges between agents and human feedback\n",
    "- Preserves full conversation history (including tool traces)\n",
    "- Routes messages between writer, human, and editor\n",
    "\n",
    "## Pipeline Layout\n",
    "\n",
    "```\n",
    "Writer Agent (with tools)\n",
    "    ↓\n",
    "DraftFeedbackCoordinator\n",
    "    ↓\n",
    "RequestInfoExecutor (human feedback)\n",
    "    ↓\n",
    "DraftFeedbackCoordinator\n",
    "    ↓\n",
    "Final Editor Agent\n",
    "```\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Azure OpenAI configured with environment variables:\n",
    "  - `AZURE_OPENAI_API_KEY`\n",
    "  - `AZURE_OPENAI_ENDPOINT`\n",
    "  - `AZURE_OPENAI_DEPLOYMENT_NAME`\n",
    "  - `AZURE_OPENAI_API_VERSION`\n",
    "- Azure CLI authentication: Run `az login` before executing\n",
    "- Agent Framework installed: `pip install agent-framework`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e075f91a",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b6c9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Annotated\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from agent_framework import (\n",
    "    AgentExecutorRequest,\n",
    "    AgentExecutorResponse,\n",
    "    AgentRunUpdateEvent,\n",
    "    ChatMessage,\n",
    "    Executor,\n",
    "    FunctionCallContent,\n",
    "    FunctionResultContent,\n",
    "    RequestInfoEvent,\n",
    "    RequestInfoExecutor,\n",
    "    RequestInfoMessage,\n",
    "    RequestResponse,\n",
    "    Role,\n",
    "    ToolMode,\n",
    "    WorkflowBuilder,\n",
    "    WorkflowContext,\n",
    "    WorkflowOutputEvent,\n",
    "    handler,\n",
    ")\n",
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "from azure.identity import AzureCliCredential\n",
    "from pydantic import Field\n",
    "# Load environment variables from .env file\n",
    "load_dotenv('../../.env')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446b73b4",
   "metadata": {},
   "source": [
    "## Define Tool Functions\n",
    "\n",
    "These Python functions will be available to the writer agent as tools. The agent can call them to gather factual information before drafting copy.\n",
    "\n",
    "### Key Points:\n",
    "- Use `Annotated` type hints with `Field(description=...)` to provide parameter documentation\n",
    "- Return string values that the agent can incorporate into its reasoning\n",
    "- Keep functions simple and focused on data retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab9708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_product_brief(\n",
    "    product_name: Annotated[str, Field(description=\"Product name to look up.\")],\n",
    ") -> str:\n",
    "    \"\"\"Return a marketing brief for a product.\"\"\"\n",
    "    briefs = {\n",
    "        \"lumenx desk lamp\": (\n",
    "            \"Product: LumenX Desk Lamp\\n\"\n",
    "            \"- Three-point adjustable arm with 270° rotation.\\n\"\n",
    "            \"- Custom warm-to-neutral LED spectrum (2700K-4000K).\\n\"\n",
    "            \"- USB-C charging pad integrated in the base.\\n\"\n",
    "            \"- Designed for home offices and late-night study sessions.\"\n",
    "        )\n",
    "    }\n",
    "    return briefs.get(product_name.lower(), f\"No stored brief for '{product_name}'.\")\n",
    "\n",
    "\n",
    "def get_brand_voice_profile(\n",
    "    voice_name: Annotated[str, Field(description=\"Brand or campaign voice to emulate.\")],\n",
    ") -> str:\n",
    "    \"\"\"Return guidance for the requested brand voice.\"\"\"\n",
    "    voices = {\n",
    "        \"lumenx launch\": (\n",
    "            \"Voice guidelines:\\n\"\n",
    "            \"- Friendly and modern with concise sentences.\\n\"\n",
    "            \"- Highlight practical benefits before aesthetics.\\n\"\n",
    "            \"- End with an invitation to imagine the product in daily use.\"\n",
    "        )\n",
    "    }\n",
    "    return voices.get(voice_name.lower(), f\"No stored voice profile for '{voice_name}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c3b279",
   "metadata": {},
   "source": [
    "## Define Request Message Type\n",
    "\n",
    "This dataclass defines the structure of feedback requests sent to the human reviewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9f9a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DraftFeedbackRequest(RequestInfoMessage):\n",
    "    \"\"\"Payload sent to RequestInfoExecutor for human review.\"\"\"\n",
    "\n",
    "    prompt: str = \"\"\n",
    "    draft_text: str = \"\"\n",
    "    conversation: list[ChatMessage] = field(default_factory=list)  # type: ignore[reportUnknownVariableType]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f195fdb4",
   "metadata": {},
   "source": [
    "## Create Custom Coordinator Executor\n",
    "\n",
    "The `DraftFeedbackCoordinator` acts as a bridge between the writer agent, human feedback, and final editor.\n",
    "\n",
    "### Handler Methods:\n",
    "\n",
    "#### 1. `on_writer_response`\n",
    "- Receives the draft from the writer agent\n",
    "- Preserves full conversation history (including tool calls)\n",
    "- Sends `DraftFeedbackRequest` to `RequestInfoExecutor`\n",
    "\n",
    "#### 2. `on_human_feedback`\n",
    "- Receives human feedback via `RequestResponse`\n",
    "- Reconstructs conversation with feedback injected\n",
    "- Forwards to final editor with instructions to incorporate feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd944446",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DraftFeedbackCoordinator(Executor):\n",
    "    \"\"\"Bridge between the writer agent, human feedback, and final editor.\"\"\"\n",
    "\n",
    "    def __init__(self, *, id: str = \"draft_feedback_coordinator\") -> None:\n",
    "        super().__init__(id)\n",
    "\n",
    "    @handler\n",
    "    async def on_writer_response(\n",
    "        self,\n",
    "        draft: AgentExecutorResponse,\n",
    "        ctx: WorkflowContext[DraftFeedbackRequest],\n",
    "    ) -> None:\n",
    "        # Preserve the full conversation so the final editor can see tool traces and the initial prompt.\n",
    "        conversation: list[ChatMessage]\n",
    "        if draft.full_conversation is not None:\n",
    "            conversation = list(draft.full_conversation)\n",
    "        else:\n",
    "            conversation = list(draft.agent_run_response.messages)\n",
    "        draft_text = draft.agent_run_response.text.strip()\n",
    "        if not draft_text:\n",
    "            draft_text = \"No draft text was produced.\"\n",
    "\n",
    "        prompt = (\n",
    "            \"Review the draft from the writer and provide a short directional note \"\n",
    "            \"(tone tweaks, must-have detail, target audience, etc.). \"\n",
    "            \"Keep it under 30 words.\"\n",
    "        )\n",
    "        await ctx.send_message(DraftFeedbackRequest(prompt=prompt, draft_text=draft_text, conversation=conversation))\n",
    "\n",
    "    @handler\n",
    "    async def on_human_feedback(\n",
    "        self,\n",
    "        feedback: RequestResponse[DraftFeedbackRequest, str],\n",
    "        ctx: WorkflowContext[AgentExecutorRequest],\n",
    "    ) -> None:\n",
    "        note = (feedback.data or \"\").strip()\n",
    "        request = feedback.original_request\n",
    "\n",
    "        conversation: list[ChatMessage] = list(request.conversation)\n",
    "        instruction = (\n",
    "            \"A human reviewer shared the following guidance:\\n\"\n",
    "            f\"{note or 'No specific guidance provided.'}\\n\\n\"\n",
    "            \"Rewrite the draft from the previous assistant message into a polished final version. \"\n",
    "            \"Keep the response under 120 words and reflect any requested tone adjustments.\"\n",
    "        )\n",
    "        conversation.append(ChatMessage(Role.USER, text=instruction))\n",
    "        await ctx.send_message(AgentExecutorRequest(messages=conversation, should_respond=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b774bfcf",
   "metadata": {},
   "source": [
    "## Build and Execute Workflow\n",
    "\n",
    "### Workflow Construction:\n",
    "\n",
    "1. **Create chat client** with Azure CLI authentication\n",
    "2. **Create writer agent** with tools and `ToolMode.REQUIRED_ANY`\n",
    "3. **Create editor agent** for final polishing\n",
    "4. **Create coordinator** to orchestrate feedback flow\n",
    "5. **Create RequestInfoExecutor** for human input\n",
    "6. **Build workflow** with edges defining the pipeline\n",
    "\n",
    "### Execution Loop:\n",
    "\n",
    "- Stream workflow events asynchronously\n",
    "- Monitor `AgentRunUpdateEvent` for tool calls and agent outputs\n",
    "- Capture `RequestInfoEvent` for human feedback prompts\n",
    "- Continue with `send_responses_streaming` after collecting feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc46a762",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_workflow() -> None:\n",
    "    \"\"\"Run the workflow and bridge human feedback between two agents.\"\"\"\n",
    "    endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    deployment_name = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "    chat_client = AzureOpenAIChatClient(\n",
    "        deployment_name=deployment_name,\n",
    "        endpoint=endpoint,\n",
    "        credential=AzureCliCredential()\n",
    "    )\n",
    "\n",
    "    writer_agent = chat_client.create_agent(\n",
    "        name=\"writer_agent\",\n",
    "        instructions=(\n",
    "            \"You are a marketing writer. Call the available tools before drafting copy so you are precise. \"\n",
    "            \"Always call both tools once before drafting. Summarize tool outputs as bullet points, then \"\n",
    "            \"produce a 3-sentence draft.\"\n",
    "        ),\n",
    "        tools=[fetch_product_brief, get_brand_voice_profile],\n",
    "        tool_choice=ToolMode.REQUIRED_ANY,\n",
    "    )\n",
    "\n",
    "    final_editor_agent = chat_client.create_agent(\n",
    "        name=\"final_editor_agent\",\n",
    "        instructions=(\n",
    "            \"You are an editor who polishes marketing copy using human guidance. \"\n",
    "            \"Respect factual details from the prior messages while applying the feedback.\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    feedback_coordinator = DraftFeedbackCoordinator()\n",
    "    request_info_executor = RequestInfoExecutor(id=\"human_feedback\")\n",
    "\n",
    "    workflow = (\n",
    "        WorkflowBuilder()\n",
    "        .add_agent(writer_agent, id=\"Writer\")\n",
    "        .add_agent(final_editor_agent, id=\"FinalEditor\", output_response=True)\n",
    "        .set_start_executor(writer_agent)\n",
    "        .add_edge(writer_agent, feedback_coordinator)\n",
    "        .add_edge(feedback_coordinator, request_info_executor)\n",
    "        .add_edge(request_info_executor, feedback_coordinator)\n",
    "        .add_edge(feedback_coordinator, final_editor_agent)\n",
    "        .build()\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        \"Interactive mode. When prompted, provide a short feedback note for the editor (type 'exit' to quit).\",\n",
    "        flush=True,\n",
    "    )\n",
    "\n",
    "    pending_responses: dict[str, str] | None = None\n",
    "    completed = False\n",
    "    printed_tool_calls: set[str] = set()\n",
    "    printed_tool_results: set[str] = set()\n",
    "\n",
    "    while not completed:\n",
    "        last_executor: str | None = None\n",
    "        stream = (\n",
    "            workflow.send_responses_streaming(pending_responses)\n",
    "            if pending_responses is not None\n",
    "            else workflow.run_stream(\n",
    "                \"Create a short launch blurb for the LumenX desk lamp. Emphasize adjustability and warm lighting.\"\n",
    "            )\n",
    "        )\n",
    "        pending_responses = None\n",
    "        requests: list[tuple[str, DraftFeedbackRequest]] = []\n",
    "\n",
    "        async for event in stream:\n",
    "            if isinstance(event, AgentRunUpdateEvent):\n",
    "                executor_id = event.executor_id\n",
    "                update = event.data\n",
    "                # Extract and print any new tool calls or results from the update.\n",
    "                function_calls = [c for c in update.contents if isinstance(c, FunctionCallContent)]  # type: ignore[union-attr]     \n",
    "                function_results = [c for c in update.contents if isinstance(c, FunctionResultContent)]  # type: ignore[union-attr] \n",
    "                if executor_id != last_executor:\n",
    "                    if last_executor is not None:\n",
    "                        print()\n",
    "                    print(f\"{executor_id}:\", end=\" \", flush=True)\n",
    "                    last_executor = executor_id\n",
    "                # Print any new tool calls before the text update.\n",
    "                for call in function_calls:\n",
    "                    if call.call_id in printed_tool_calls:\n",
    "                        continue\n",
    "                    printed_tool_calls.add(call.call_id)\n",
    "                    args = call.arguments\n",
    "                    if isinstance(args, dict):\n",
    "                        args_preview = json.dumps(args, ensure_ascii=False)\n",
    "                    else:\n",
    "                        args_preview = (args or \"\").strip()\n",
    "                    print(\n",
    "                        f\"\\n{executor_id} [tool-call] {call.name}({args_preview})\",\n",
    "                        flush=True,\n",
    "                    )\n",
    "                    print(f\"{executor_id}:\", end=\" \", flush=True)\n",
    "                # Print any new tool results before the text update.\n",
    "                for result in function_results:\n",
    "                    if result.call_id in printed_tool_results:\n",
    "                        continue\n",
    "                    printed_tool_results.add(result.call_id)\n",
    "                    result_text = result.result\n",
    "                    if not isinstance(result_text, str):\n",
    "                        result_text = json.dumps(result_text, ensure_ascii=False)\n",
    "                    print(\n",
    "                        f\"\\n{executor_id} [tool-result] {result.call_id}: {result_text}\",\n",
    "                        flush=True,\n",
    "                    )\n",
    "                    print(f\"{executor_id}:\", end=\" \", flush=True)\n",
    "                # Finally, print the text update.\n",
    "                print(update, end=\"\", flush=True)\n",
    "            elif isinstance(event, RequestInfoEvent) and isinstance(event.data, DraftFeedbackRequest):\n",
    "                # Stash the request so we can prompt the human after the stream completes.\n",
    "                requests.append((event.request_id, event.data))\n",
    "                last_executor = None\n",
    "            elif isinstance(event, WorkflowOutputEvent):\n",
    "                last_executor = None\n",
    "                response = event.data\n",
    "                print(\"\\n===== Final output =====\")\n",
    "                final_text = getattr(response, \"text\", str(response))\n",
    "                print(final_text.strip())\n",
    "                completed = True\n",
    "\n",
    "        if requests and not completed:\n",
    "            responses: dict[str, str] = {}\n",
    "            for request_id, request in requests:\n",
    "                print(\"\\n----- Writer draft -----\")\n",
    "                print(request.draft_text.strip())\n",
    "                print(\"\\nProvide guidance for the editor (or press Enter to accept the draft).\")\n",
    "                answer = input(\"Human feedback: \").strip()  # noqa: ASYNC250\n",
    "                if answer.lower() == \"exit\":\n",
    "                    print(\"Exiting...\")\n",
    "                    return\n",
    "                responses[request_id] = answer\n",
    "            pending_responses = responses\n",
    "\n",
    "    print(\"Workflow complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256cc968",
   "metadata": {},
   "source": [
    "## Run the Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23d3ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "await run_workflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a55bc6c",
   "metadata": {},
   "source": [
    "## Expected Output\n",
    "\n",
    "```\n",
    "Interactive mode. When prompted, provide a short feedback note for the editor (type 'exit' to quit).\n",
    "Writer: [tool-call] fetch_product_brief({\"product_name\": \"lumenx desk lamp\"})\n",
    "Writer: [tool-result] call_xxx: Product: LumenX Desk Lamp...\n",
    "Writer: [tool-call] get_brand_voice_profile({\"voice_name\": \"lumenx launch\"})\n",
    "Writer: [tool-result] call_yyy: Voice guidelines...\n",
    "Writer: Meet the LumenX Desk Lamp—your perfect companion for focused work...\n",
    "\n",
    "----- Writer draft -----\n",
    "Meet the LumenX Desk Lamp—your perfect companion for focused work...\n",
    "\n",
    "Provide guidance for the editor (or press Enter to accept the draft).\n",
    "Human feedback: Make it more energetic and emphasize the USB charging\n",
    "\n",
    "FinalEditor: Transform your workspace with the LumenX Desk Lamp! ...\n",
    "\n",
    "===== Final output =====\n",
    "Transform your workspace with the LumenX Desk Lamp! ...\n",
    "Workflow complete.\n",
    "```\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "### 1. Tool Integration\n",
    "- Attach functions to agents via `tools=[...]`\n",
    "- Use `ToolMode.REQUIRED_ANY` to enforce tool usage\n",
    "- Monitor `FunctionCallContent` and `FunctionResultContent` in updates\n",
    "\n",
    "### 2. Human-in-the-Loop Pattern\n",
    "- `RequestInfoExecutor` provides built-in pause-for-input capability\n",
    "- `RequestInfoEvent` signals when input is needed\n",
    "- `send_responses_streaming()` resumes workflow with collected responses\n",
    "\n",
    "### 3. Conversation Preservation\n",
    "- Save `full_conversation` to retain tool traces\n",
    "- Pass complete history to downstream agents for context\n",
    "- Enables the editor to see *how* the writer reached its conclusion\n",
    "\n",
    "### 4. Custom Coordinator Pattern\n",
    "- Create specialized executors to orchestrate complex flows\n",
    "- Use multiple `@handler` methods to process different message types\n",
    "- Type hints on `WorkflowContext` determine routing behavior\n",
    "\n",
    "### 5. Interactive Streaming\n",
    "- Process events asynchronously with `async for`\n",
    "- Display incremental updates for better UX\n",
    "- Collect feedback requests and resume with `send_responses_streaming()`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}