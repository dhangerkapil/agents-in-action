{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29b66877",
   "metadata": {},
   "source": [
    "# Workflow as Agent with Reflection and Retry Pattern\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates an advanced **reflection and retry pattern** where:\n",
    "1. A **Worker** executor generates responses to user queries\n",
    "2. A **Reviewer** executor evaluates the quality using an LLM-based review\n",
    "3. If not approved, the Worker regenerates the response incorporating feedback\n",
    "4. This cycle continues until the Reviewer approves the output\n",
    "5. Only approved responses are emitted externally via `AgentRunUpdateEvent`\n",
    "\n",
    "The entire workflow is wrapped as an agent using `WorkflowAgent`, allowing it to be used like any standard agent with `run()` and `run_stream()` methods.\n",
    "\n",
    "## Key Concepts Demonstrated\n",
    "\n",
    "### 1. WorkflowAgent\n",
    "- Wraps a workflow to behave like a regular agent\n",
    "- Enables workflows to be composed as building blocks in larger systems\n",
    "- Handles internal message routing while exposing standard agent interface\n",
    "\n",
    "### 2. Cyclic Workflow Design\n",
    "- **Worker ↔ Reviewer**: Bidirectional edges enable iterative improvement\n",
    "- Unlike linear pipelines, cyclic workflows support feedback loops\n",
    "- Workflow completes when idle (no pending messages)\n",
    "\n",
    "### 3. AgentRunUpdateEvent\n",
    "- Mechanism for emitting approved responses to external consumers\n",
    "- Only approved outputs are surfaced outside the workflow\n",
    "- Internal iterations remain hidden from the caller\n",
    "\n",
    "### 4. Structured Output Parsing\n",
    "- Uses Pydantic models with `response_format` parameter\n",
    "- Ensures consistent, parseable feedback from the Reviewer\n",
    "- Enables programmatic approval decisions\n",
    "\n",
    "### 5. State Management\n",
    "- Worker tracks pending requests via `_pending_requests` dictionary\n",
    "- Correlates review responses with original requests using `request_id`\n",
    "- Maintains conversation history across retry iterations\n",
    "\n",
    "## Pipeline Layout\n",
    "\n",
    "```\n",
    "User Query\n",
    "    ↓\n",
    "Worker (generates response)\n",
    "    ↓\n",
    "Reviewer (evaluates quality)\n",
    "    ↓ (if not approved)\n",
    "Worker (regenerates with feedback) ──┐\n",
    "    ↓                                 │\n",
    "Reviewer (re-evaluates)               │\n",
    "    └─────────────────────────────────┘\n",
    "    ↓ (if approved)\n",
    "AgentRunUpdateEvent (emit to external consumer)\n",
    "```\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- OpenAI API key configured (environment variable `OPENAI_API_KEY`)\n",
    "- Agent Framework installed: `pip install agent-framework`\n",
    "- Understanding of `WorkflowBuilder`, `Executor`, `WorkflowContext`, and event handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e26c49d",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373dd562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from dataclasses import dataclass\n",
    "from uuid import uuid4\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from agent_framework import (\n",
    "    AgentRunResponseUpdate,\n",
    "    AgentRunUpdateEvent,\n",
    "    ChatClientProtocol,\n",
    "    ChatMessage,\n",
    "    Contents,\n",
    "    Executor,\n",
    "    Role,\n",
    "    WorkflowBuilder,\n",
    "    WorkflowContext,\n",
    "    handler,\n",
    ")\n",
    "from agent_framework.openai import OpenAIChatClient\n",
    "from pydantic import BaseModel\n",
    "# Load environment variables from .env file\n",
    "load_dotenv('../../.env')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d651e609",
   "metadata": {},
   "source": [
    "## Define Message Types\n",
    "\n",
    "### ReviewRequest\n",
    "Structured request passed from Worker to Reviewer containing:\n",
    "- `request_id`: Unique identifier for correlation\n",
    "- `user_messages`: Original user query messages\n",
    "- `agent_messages`: Worker's generated response messages\n",
    "\n",
    "### ReviewResponse\n",
    "Structured response from Reviewer back to Worker containing:\n",
    "- `request_id`: Correlates with the original request\n",
    "- `feedback`: Actionable guidance for improvement\n",
    "- `approved`: Boolean indicating whether to emit or retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c92fdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ReviewRequest:\n",
    "    \"\"\"Structured request passed from Worker to Reviewer for evaluation.\"\"\"\n",
    "    request_id: str\n",
    "    user_messages: list[ChatMessage]\n",
    "    agent_messages: list[ChatMessage]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ReviewResponse:\n",
    "    \"\"\"Structured response from Reviewer back to Worker.\"\"\"\n",
    "    request_id: str\n",
    "    feedback: str\n",
    "    approved: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e53e511",
   "metadata": {},
   "source": [
    "## Create Reviewer Executor\n",
    "\n",
    "The Reviewer uses an LLM to evaluate responses against quality criteria:\n",
    "- **Relevance**: Does the response address the query?\n",
    "- **Accuracy**: Is the information correct?\n",
    "- **Clarity**: Is it easy to understand?\n",
    "- **Completeness**: Does it cover all aspects?\n",
    "\n",
    "### Key Implementation Details:\n",
    "\n",
    "1. **Structured Output**: Uses Pydantic `BaseModel` with `response_format` to ensure parseable feedback\n",
    "2. **Conversation Context**: Includes both user and agent messages for full context\n",
    "3. **Review Instructions**: System prompt defines evaluation criteria\n",
    "4. **Typed Context**: `WorkflowContext[ReviewResponse]` ensures type-safe message routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a085b995",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reviewer(Executor):\n",
    "    \"\"\"Executor that reviews agent responses and provides structured feedback.\"\"\"\n",
    "\n",
    "    def __init__(self, id: str, chat_client: ChatClientProtocol) -> None:\n",
    "        super().__init__(id=id)\n",
    "        self._chat_client = chat_client\n",
    "\n",
    "    @handler\n",
    "    async def review(self, request: ReviewRequest, ctx: WorkflowContext[ReviewResponse]) -> None:\n",
    "        print(f\"Reviewer: Evaluating response for request {request.request_id[:8]}...\")\n",
    "\n",
    "        # Define structured schema for the LLM to return.\n",
    "        class _Response(BaseModel):\n",
    "            feedback: str\n",
    "            approved: bool\n",
    "\n",
    "        # Construct review instructions and context.\n",
    "        messages = [\n",
    "            ChatMessage(\n",
    "                role=Role.SYSTEM,\n",
    "                text=(\n",
    "                    \"You are a reviewer for an AI agent. Provide feedback on the \"\n",
    "                    \"exchange between a user and the agent. Indicate approval only if:\\n\"\n",
    "                    \"- Relevance: response addresses the query\\n\"\n",
    "                    \"- Accuracy: information is correct\\n\"\n",
    "                    \"- Clarity: response is easy to understand\\n\"\n",
    "                    \"- Completeness: response covers all aspects\\n\"\n",
    "                    \"Do not approve until all criteria are satisfied.\"\n",
    "                ),\n",
    "            )\n",
    "        ]\n",
    "        # Add conversation history.\n",
    "        messages.extend(request.user_messages)\n",
    "        messages.extend(request.agent_messages)\n",
    "\n",
    "        # Add explicit review instruction.\n",
    "        messages.append(ChatMessage(role=Role.USER, text=\"Please review the agent's responses.\"))\n",
    "\n",
    "        print(\"Reviewer: Sending review request to LLM...\")\n",
    "        response = await self._chat_client.get_response(messages=messages, response_format=_Response)\n",
    "\n",
    "        parsed = _Response.model_validate_json(response.messages[-1].text)\n",
    "\n",
    "        print(f\"Reviewer: Review complete - Approved: {parsed.approved}\")\n",
    "        print(f\"Reviewer: Feedback: {parsed.feedback}\")\n",
    "\n",
    "        # Send structured review result to Worker.\n",
    "        await ctx.send_message(\n",
    "            ReviewResponse(request_id=request.request_id, feedback=parsed.feedback, approved=parsed.approved)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76b4e69",
   "metadata": {},
   "source": [
    "## Create Worker Executor\n",
    "\n",
    "The Worker generates responses and incorporates feedback when necessary.\n",
    "\n",
    "### Handler Methods:\n",
    "\n",
    "#### 1. `handle_user_messages`\n",
    "- Entry point for new user queries\n",
    "- Generates initial response using chat client\n",
    "- Creates `ReviewRequest` and sends to Reviewer\n",
    "- Tracks request in `_pending_requests` for correlation\n",
    "\n",
    "#### 2. `handle_review_response`\n",
    "- Receives `ReviewResponse` from Reviewer\n",
    "- If approved: Emits `AgentRunUpdateEvent` to external consumer\n",
    "- If not approved: Incorporates feedback and regenerates response\n",
    "- Creates new `ReviewRequest` for re-evaluation\n",
    "\n",
    "### State Management:\n",
    "- `_pending_requests`: Maps `request_id` to (ReviewRequest, conversation history)\n",
    "- Enables correlation of review responses with original requests\n",
    "- Maintains conversation context across retry iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caa1ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Worker(Executor):\n",
    "    \"\"\"Executor that generates responses and incorporates feedback when necessary.\"\"\"\n",
    "\n",
    "    def __init__(self, id: str, chat_client: ChatClientProtocol) -> None:\n",
    "        super().__init__(id=id)\n",
    "        self._chat_client = chat_client\n",
    "        self._pending_requests: dict[str, tuple[ReviewRequest, list[ChatMessage]]] = {}\n",
    "\n",
    "    @handler\n",
    "    async def handle_user_messages(self, user_messages: list[ChatMessage], ctx: WorkflowContext[ReviewRequest]) -> None:\n",
    "        print(\"Worker: Received user messages, generating response...\")\n",
    "\n",
    "        # Initialize chat with system prompt.\n",
    "        messages = [ChatMessage(role=Role.SYSTEM, text=\"You are a helpful assistant.\")]\n",
    "        messages.extend(user_messages)\n",
    "\n",
    "        print(\"Worker: Calling LLM to generate response...\")\n",
    "        response = await self._chat_client.get_response(messages=messages)\n",
    "        print(f\"Worker: Response generated: {response.messages[-1].text}\")\n",
    "\n",
    "        # Add agent messages to context.\n",
    "        messages.extend(response.messages)\n",
    "\n",
    "        # Create review request and send to Reviewer.\n",
    "        request = ReviewRequest(request_id=str(uuid4()), user_messages=user_messages, agent_messages=response.messages)\n",
    "        print(f\"Worker: Sending response for review (ID: {request.request_id[:8]})\")\n",
    "        await ctx.send_message(request)\n",
    "\n",
    "        # Track request for possible retry.\n",
    "        self._pending_requests[request.request_id] = (request, messages)\n",
    "\n",
    "    @handler\n",
    "    async def handle_review_response(self, review: ReviewResponse, ctx: WorkflowContext[ReviewRequest]) -> None:\n",
    "        print(f\"Worker: Received review for request {review.request_id[:8]} - Approved: {review.approved}\")\n",
    "\n",
    "        if review.request_id not in self._pending_requests:\n",
    "            raise ValueError(f\"Unknown request ID in review: {review.request_id}\")\n",
    "\n",
    "        request, messages = self._pending_requests.pop(review.request_id)\n",
    "\n",
    "        if review.approved:\n",
    "            print(\"Worker: Response approved. Emitting to external consumer...\")\n",
    "            contents: list[Contents] = []\n",
    "            for message in request.agent_messages:\n",
    "                contents.extend(message.contents)\n",
    "\n",
    "            # Emit approved result to external consumer via AgentRunUpdateEvent.\n",
    "            await ctx.add_event(\n",
    "                AgentRunUpdateEvent(self.id, data=AgentRunResponseUpdate(contents=contents, role=Role.ASSISTANT))\n",
    "            )\n",
    "            return\n",
    "\n",
    "        print(f\"Worker: Response not approved. Feedback: {review.feedback}\")\n",
    "        print(\"Worker: Regenerating response with feedback...\")\n",
    "\n",
    "        # Incorporate review feedback.\n",
    "        messages.append(ChatMessage(role=Role.SYSTEM, text=review.feedback))\n",
    "        messages.append(\n",
    "            ChatMessage(role=Role.SYSTEM, text=\"Please incorporate the feedback and regenerate the response.\")\n",
    "        )\n",
    "        messages.extend(request.user_messages)\n",
    "\n",
    "        # Retry with updated prompt.\n",
    "        response = await self._chat_client.get_response(messages=messages)\n",
    "        print(f\"Worker: New response generated: {response.messages[-1].text}\")\n",
    "\n",
    "        messages.extend(response.messages)\n",
    "\n",
    "        # Send updated request for re-review.\n",
    "        new_request = ReviewRequest(\n",
    "            request_id=review.request_id, user_messages=request.user_messages, agent_messages=response.messages\n",
    "        )\n",
    "        await ctx.send_message(new_request)\n",
    "\n",
    "        # Track new request for further evaluation.\n",
    "        self._pending_requests[new_request.request_id] = (new_request, messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8dad64",
   "metadata": {},
   "source": [
    "## Build Workflow and Wrap as Agent\n",
    "\n",
    "### Workflow Construction:\n",
    "\n",
    "1. **Create chat clients**: Mini model for Worker, full model for Reviewer\n",
    "2. **Create executors**: Worker and Reviewer instances\n",
    "3. **Add bidirectional edges**: Worker ↔ Reviewer for cyclic feedback\n",
    "4. **Set start executor**: Worker receives initial user messages\n",
    "5. **Convert to agent**: `.as_agent()` wraps workflow with agent interface\n",
    "\n",
    "### Key Points:\n",
    "\n",
    "- **Bidirectional edges** enable the reflection pattern (Worker can send to Reviewer, Reviewer can send to Worker)\n",
    "- **`.as_agent()`** allows the workflow to be used like any standard agent\n",
    "- **Streaming execution** with `run_stream()` shows incremental updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc73bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_reflection_workflow() -> None:\n",
    "    print(\"Starting Workflow Agent Demo\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Initialize chat clients and executors.\n",
    "    print(\"Creating chat client and executors...\")\n",
    "    mini_chat_client = OpenAIChatClient(model_id=\"gpt-4o-mini\")\n",
    "    chat_client = OpenAIChatClient(model_id=\"gpt-4o\")\n",
    "    reviewer = Reviewer(id=\"reviewer\", chat_client=chat_client)\n",
    "    worker = Worker(id=\"worker\", chat_client=mini_chat_client)\n",
    "\n",
    "    print(\"Building workflow with Worker ↔ Reviewer cycle...\")\n",
    "    agent = (\n",
    "        WorkflowBuilder()\n",
    "        .add_edge(worker, reviewer)  # Worker sends responses to Reviewer\n",
    "        .add_edge(reviewer, worker)  # Reviewer provides feedback to Worker\n",
    "        .set_start_executor(worker)\n",
    "        .build()\n",
    "        .as_agent()  # Wrap workflow as an agent\n",
    "    )\n",
    "\n",
    "    print(\"Running workflow agent with user query...\")\n",
    "    print(\"Query: 'Write code for parallel reading 1 million files on disk and write to a sorted output file.'\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Run agent in streaming mode to observe incremental updates.\n",
    "    async for event in agent.run_stream(\n",
    "        \"Write code for parallel reading 1 million files on disk and write to a sorted output file.\"\n",
    "    ):\n",
    "        print(f\"Agent Response: {event}\")\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Workflow completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34c8d4e",
   "metadata": {},
   "source": [
    "## Run the Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a995a2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "await run_reflection_workflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e5ffbf",
   "metadata": {},
   "source": [
    "## Expected Output\n",
    "\n",
    "```\n",
    "Starting Workflow Agent Demo\n",
    "==================================================\n",
    "Creating chat client and executors...\n",
    "Building workflow with Worker ↔ Reviewer cycle...\n",
    "Running workflow agent with user query...\n",
    "Query: 'Write code for parallel reading 1 million files on disk and write to a sorted output file.'\n",
    "--------------------------------------------------\n",
    "Worker: Received user messages, generating response...\n",
    "Worker: Calling LLM to generate response...\n",
    "Worker: Response generated: Here's a Python implementation...\n",
    "Worker: Sending response for review (ID: 12345678)\n",
    "Reviewer: Evaluating response for request 12345678...\n",
    "Reviewer: Sending review request to LLM...\n",
    "Reviewer: Review complete - Approved: False\n",
    "Reviewer: Feedback: The response lacks error handling and doesn't explain sorting mechanism.\n",
    "Worker: Received review for request 12345678 - Approved: False\n",
    "Worker: Response not approved. Feedback: The response lacks error handling...\n",
    "Worker: Regenerating response with feedback...\n",
    "Worker: Calling LLM to generate response...\n",
    "Worker: New response generated: Here's an improved implementation with error handling...\n",
    "Worker: Sending response for review (ID: 12345678)\n",
    "Reviewer: Evaluating response for request 12345678...\n",
    "Reviewer: Review complete - Approved: True\n",
    "Reviewer: Feedback: All criteria met. Well-structured code with proper error handling.\n",
    "Worker: Received review for request 12345678 - Approved: True\n",
    "Worker: Response approved. Emitting to external consumer...\n",
    "Agent Response: <AgentRunResponseUpdate with approved code>\n",
    "==================================================\n",
    "Workflow completed!\n",
    "```\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "### 1. Reflection Pattern Architecture\n",
    "- **Cyclic workflows** enable iterative refinement through feedback loops\n",
    "- Worker generates → Reviewer evaluates → Worker refines (repeat until approved)\n",
    "- Only approved outputs are emitted to external consumers\n",
    "\n",
    "### 2. WorkflowAgent Benefits\n",
    "- Wraps complex internal workflows with simple agent interface\n",
    "- Hides internal iterations from external callers\n",
    "- Enables workflow composition and reuse\n",
    "\n",
    "### 3. Structured Feedback\n",
    "- Use Pydantic models with `response_format` for parseable LLM outputs\n",
    "- Ensures consistent approval/rejection decisions\n",
    "- Enables programmatic routing based on feedback\n",
    "\n",
    "### 4. State Management\n",
    "- Track pending requests using dictionaries keyed by `request_id`\n",
    "- Correlate responses with original requests\n",
    "- Maintain conversation history across iterations\n",
    "\n",
    "### 5. Event Emission\n",
    "- `AgentRunUpdateEvent` emits approved content to external consumers\n",
    "- `ctx.add_event()` publishes events from within executors\n",
    "- External callers only see final approved results\n",
    "\n",
    "### 6. Production Considerations\n",
    "- **Add iteration limits** to prevent infinite loops (e.g., max 3 retries)\n",
    "- **Log all iterations** for debugging and analysis\n",
    "- **Cache intermediate results** to avoid redundant LLM calls\n",
    "- **Monitor costs** as each iteration incurs LLM API costs\n",
    "- **Consider timeouts** for long-running review cycles\n",
    "\n",
    "### 7. When to Use This Pattern\n",
    "- **Quality-critical outputs**: Code generation, legal documents, medical advice\n",
    "- **Multi-stage reasoning**: Complex queries requiring iterative refinement\n",
    "- **Self-improvement**: Agents that learn from feedback\n",
    "- **Compliance checks**: Automated validation against policies/standards"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}