{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac126861",
   "metadata": {},
   "source": [
    "# Sequential Workflow with Custom Executors\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates mixing agents and **custom executors** in a sequential workflow. We'll create a pipeline where:\n",
    "1. A content agent generates detailed text\n",
    "2. A custom summarizer executor processes the conversation\n",
    "\n",
    "This pattern shows how to create custom executors that work with the shared conversation context in sequential orchestration.\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "1. **Mixing Participants**: Combine agents and custom executors\n",
    "2. **Custom Executor Contract**: Accept `list[ChatMessage]`, emit updated list\n",
    "3. **Conversation Processing**: Read, transform, and append to shared context\n",
    "4. **Internal Adapters**: Automatic conversion between agent and executor formats\n",
    "\n",
    "### Architecture:\n",
    "\n",
    "```\n",
    "User Prompt\n",
    "    ↓\n",
    "[input-conversation]\n",
    "    ↓\n",
    "Content Agent (generates paragraph)\n",
    "    ↓\n",
    "[to-conversation:content]\n",
    "    ↓\n",
    "Summarizer Executor (custom)\n",
    "    ↓\n",
    "[complete]\n",
    "    ↓\n",
    "Final Conversation with Summary\n",
    "```\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Azure OpenAI configured with environment variables\n",
    "- Azure CLI authentication: Run `az login`\n",
    "- Agent Framework installed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1d15dd",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469dacc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from typing import Any\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from agent_framework import (\n",
    "    ChatMessage,\n",
    "    Executor,\n",
    "    Role,\n",
    "    SequentialBuilder,\n",
    "    WorkflowContext,\n",
    "    handler,\n",
    ")\n",
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "from azure.identity import AzureCliCredential\n",
    "from typing_extensions import Never\n",
    "# Load environment variables from .env file\n",
    "load_dotenv('../../.env')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413b9cab",
   "metadata": {},
   "source": [
    "## Create Custom Summarizer Executor\n",
    "\n",
    "### Custom Executor Requirements:\n",
    "\n",
    "1. **Handler signature**: Accept `list[ChatMessage]` and `WorkflowContext[list[ChatMessage]]`\n",
    "2. **Processing**: Read the conversation, analyze it\n",
    "3. **Output**: Emit updated conversation via `ctx.yield_output()`\n",
    "\n",
    "### Our Summarizer:\n",
    "- Counts user and assistant messages\n",
    "- Appends a summary message to the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9016ecab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Summarizer(Executor):\n",
    "    \"\"\"Simple summarizer: consumes full conversation and appends an assistant summary.\"\"\"\n",
    "\n",
    "    @handler\n",
    "    async def summarize(self, conversation: list[ChatMessage], ctx: WorkflowContext[Never, list[ChatMessage]]) -> None:\n",
    "        users = sum(1 for m in conversation if m.role == Role.USER)\n",
    "        assistants = sum(1 for m in conversation if m.role == Role.ASSISTANT)\n",
    "        summary = ChatMessage(role=Role.ASSISTANT, text=f\"Summary -> users:{users} assistants:{assistants}\")\n",
    "        final_conversation = list(conversation) + [summary]\n",
    "        await ctx.yield_output(final_conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cdac7d",
   "metadata": {},
   "source": [
    "## Build and Execute Sequential Workflow\n",
    "\n",
    "### Participant Order:\n",
    "1. **Content agent**: Generates detailed response\n",
    "2. **Summarizer executor**: Processes and summarizes conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe6c25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_sequential_custom_executors() -> None:\n",
    "    # Create content agent\n",
    "    endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    deployment_name = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "    chat_client = AzureOpenAIChatClient(\n",
    "        deployment_name=deployment_name,\n",
    "        endpoint=endpoint,\n",
    "        credential=AzureCliCredential()\n",
    "    )\n",
    "    content = chat_client.create_agent(\n",
    "        instructions=\"Produce a concise paragraph answering the user's request.\",\n",
    "        name=\"content\",\n",
    "    )\n",
    "\n",
    "    # Build sequential workflow: content -> summarizer\n",
    "    summarizer = Summarizer(id=\"summarizer\")\n",
    "    workflow = SequentialBuilder().participants([content, summarizer]).build()\n",
    "\n",
    "    # Run and print final conversation\n",
    "    events = await workflow.run(\"Explain the benefits of budget eBikes for commuters.\")\n",
    "    outputs = events.get_outputs()\n",
    "\n",
    "    if outputs:\n",
    "        print(\"===== Final Conversation =====\")\n",
    "        messages: list[ChatMessage] | Any = outputs[0]\n",
    "        for i, msg in enumerate(messages, start=1):\n",
    "            name = msg.author_name or (\"assistant\" if msg.role == Role.ASSISTANT else \"user\")\n",
    "            print(f\"{'-' * 60}\\n{i:02d} [{name}]\\n{msg.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7bb439",
   "metadata": {},
   "source": [
    "## Run the Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8520a0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "await run_sequential_custom_executors()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a932a709",
   "metadata": {},
   "source": [
    "## Expected Output\n",
    "\n",
    "```\n",
    "===== Final Conversation =====\n",
    "------------------------------------------------------------\n",
    "01 [user]\n",
    "Explain the benefits of budget eBikes for commuters.\n",
    "------------------------------------------------------------\n",
    "02 [content]\n",
    "Budget eBikes offer commuters an affordable, eco-friendly alternative to cars and public transport.\n",
    "Their electric assistance reduces physical strain and allows riders to cover longer distances quickly,\n",
    "minimizing travel time and fatigue. Budget models are low-cost to maintain and operate, making them accessible\n",
    "for a wider range of people. Additionally, eBikes help reduce traffic congestion and carbon emissions,\n",
    "supporting greener urban environments. Overall, budget eBikes provide cost-effective, efficient, and\n",
    "sustainable transportation for daily commuting needs.\n",
    "------------------------------------------------------------\n",
    "03 [assistant]\n",
    "Summary -> users:1 assistants:1\n",
    "```\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "### 1. Custom Executor Handler Contract\n",
    "```python\n",
    "@handler\n",
    "async def handler_name(\n",
    "    self,\n",
    "    conversation: list[ChatMessage],\n",
    "    ctx: WorkflowContext[Never, list[ChatMessage]]\n",
    ") -> None:\n",
    "    # Process conversation\n",
    "    # Emit updated conversation\n",
    "    await ctx.yield_output(updated_conversation)\n",
    "```\n",
    "\n",
    "### 2. Mixing Agents and Executors\n",
    "- Agents and executors can be freely mixed in `.participants([...])`\n",
    "- Internal adapters handle format conversions\n",
    "- Shared conversation context flows through all\n",
    "\n",
    "### 3. Conversation Processing Patterns\n",
    "\n",
    "#### Counting/Analysis:\n",
    "```python\n",
    "users = sum(1 for m in conversation if m.role == Role.USER)\n",
    "assistants = sum(1 for m in conversation if m.role == Role.ASSISTANT)\n",
    "```\n",
    "\n",
    "#### Content Extraction:\n",
    "```python\n",
    "last_assistant = next(\n",
    "    (m for m in reversed(conversation) if m.role == Role.ASSISTANT),\n",
    "    None\n",
    ")\n",
    "```\n",
    "\n",
    "#### Transformation:\n",
    "```python\n",
    "processed = [transform_message(m) for m in conversation]\n",
    "```\n",
    "\n",
    "### 4. Appending to Conversation\n",
    "```python\n",
    "# Create new message\n",
    "summary = ChatMessage(role=Role.ASSISTANT, text=\"...\")\n",
    "\n",
    "# Append to conversation\n",
    "final_conversation = list(conversation) + [summary]\n",
    "\n",
    "# Emit via context\n",
    "await ctx.yield_output(final_conversation)\n",
    "```\n",
    "\n",
    "### 5. Use Cases for Custom Executors\n",
    "\n",
    "#### Analytics Executor:\n",
    "```python\n",
    "class AnalyticsExecutor(Executor):\n",
    "    @handler\n",
    "    async def analyze(self, conversation, ctx):\n",
    "        metrics = {\n",
    "            \"total_tokens\": calculate_tokens(conversation),\n",
    "            \"sentiment\": analyze_sentiment(conversation),\n",
    "            \"topics\": extract_topics(conversation)\n",
    "        }\n",
    "        await ctx.yield_output(conversation)  # Pass through unchanged\n",
    "        # Log metrics separately\n",
    "```\n",
    "\n",
    "#### Validation Executor:\n",
    "```python\n",
    "class ValidationExecutor(Executor):\n",
    "    @handler\n",
    "    async def validate(self, conversation, ctx):\n",
    "        last_response = conversation[-1].text\n",
    "        if not meets_criteria(last_response):\n",
    "            error_msg = ChatMessage(\n",
    "                role=Role.SYSTEM,\n",
    "                text=\"Validation failed: regenerate response\"\n",
    "            )\n",
    "            await ctx.yield_output(conversation + [error_msg])\n",
    "        else:\n",
    "            await ctx.yield_output(conversation)\n",
    "```\n",
    "\n",
    "#### Formatting Executor:\n",
    "```python\n",
    "class FormattingExecutor(Executor):\n",
    "    @handler\n",
    "    async def format(self, conversation, ctx):\n",
    "        formatted = ChatMessage(\n",
    "            role=Role.ASSISTANT,\n",
    "            text=format_as_markdown(conversation)\n",
    "        )\n",
    "        await ctx.yield_output(conversation + [formatted])\n",
    "```\n",
    "\n",
    "### 6. Internal Adapter Nodes\n",
    "Sequential workflows include:\n",
    "- **`input-conversation`**: Normalizes input to list[ChatMessage]\n",
    "- **`to-conversation:<participant>`**: Converts agent responses\n",
    "- **`complete`**: Signals completion\n",
    "\n",
    "These appear in event streams but can be safely ignored when focusing on your agents/executors.\n",
    "\n",
    "### 7. WorkflowContext Usage\n",
    "- **`ctx.yield_output(data)`**: Emit final workflow output\n",
    "- **`ctx.send_message(data)`**: Send to next executor (if in non-sequential workflow)\n",
    "- **`ctx.add_event(event)`**: Emit custom events\n",
    "\n",
    "### 8. Production Considerations\n",
    "- Keep custom executors lightweight and focused\n",
    "- Add error handling for malformed conversations\n",
    "- Log executor processing for debugging\n",
    "- Consider timeout handling for complex processing\n",
    "- Test custom executors independently before integration"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}