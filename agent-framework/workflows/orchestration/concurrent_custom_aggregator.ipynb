{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46b6607e",
   "metadata": {},
   "source": [
    "# Concurrent Orchestration with Custom Aggregator\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to **override the default aggregator** in concurrent workflows with a custom async callback function. Instead of simply collecting ChatMessages, we'll use an LLM to synthesize a concise, consolidated summary from multiple domain experts' outputs.\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "1. **Custom Aggregator**: Override default with `.with_aggregator(callback)`\n",
    "2. **LLM-based Synthesis**: Use chat client to consolidate expert outputs\n",
    "3. **Flexible Output**: Return any type (string, dict, custom object)\n",
    "4. **Result Processing**: Access `AgentExecutorResponse` list from all participants\n",
    "\n",
    "### Architecture:\n",
    "\n",
    "```\n",
    "User Prompt\n",
    "    ↓\n",
    "[Internal Dispatcher]\n",
    "   ↙     ↓      ↘\n",
    "Researcher  Marketer  Legal\n",
    "   ↘     ↓      ↙\n",
    "[Custom Aggregator: LLM Synthesis]\n",
    "    ↓\n",
    "Consolidated Summary (string)\n",
    "```\n",
    "\n",
    "### Default vs. Custom Aggregator:\n",
    "\n",
    "| Feature | Default Aggregator | Custom Aggregator |\n",
    "|---------|-------------------|------------------|\n",
    "| **Output Type** | `list[ChatMessage]` | Any type you define |\n",
    "| **Processing** | Simple concatenation | Custom logic (e.g., LLM synthesis) |\n",
    "| **Use Case** | Raw agent responses | Summarization, scoring, selection |\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Azure OpenAI configured with environment variables\n",
    "- Azure CLI authentication: Run `az login`\n",
    "- Agent Framework installed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3cf1f9",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc616505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from typing import Any\n",
    "\n",
    "from agent_framework import ChatMessage, ConcurrentBuilder, Role\n",
    "from agent_framework.azure import AzureOpenAIChatClient\n",
    "from azure.identity import AzureCliCredential\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv('../../.env')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3c6d12",
   "metadata": {},
   "source": [
    "## Define Custom Aggregator Function\n",
    "\n",
    "The aggregator callback receives `list[AgentExecutorResponse]` and returns any type.\n",
    "\n",
    "### Implementation Steps:\n",
    "1. Extract final assistant message from each agent\n",
    "2. Format as sections for the summarizer LLM\n",
    "3. Call LLM with consolidation instructions\n",
    "4. Return synthesized summary as string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1df2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_concurrent_with_custom_aggregator() -> None:\n",
    "    endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    deployment_name = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "    chat_client = AzureOpenAIChatClient(\n",
    "        deployment_name=deployment_name,\n",
    "        endpoint=endpoint,\n",
    "        credential=AzureCliCredential()\n",
    "    )\n",
    "\n",
    "    researcher = chat_client.create_agent(\n",
    "        instructions=(\n",
    "            \"You're an expert market and product researcher. Given a prompt, provide concise, factual insights,\"\n",
    "            \" opportunities, and risks.\"\n",
    "        ),\n",
    "        name=\"researcher\",\n",
    "    )\n",
    "    marketer = chat_client.create_agent(\n",
    "        instructions=(\n",
    "            \"You're a creative marketing strategist. Craft compelling value propositions and target messaging\"\n",
    "            \" aligned to the prompt.\"\n",
    "        ),\n",
    "        name=\"marketer\",\n",
    "    )\n",
    "    legal = chat_client.create_agent(\n",
    "        instructions=(\n",
    "            \"You're a cautious legal/compliance reviewer. Highlight constraints, disclaimers, and policy concerns\"\n",
    "            \" based on the prompt.\"\n",
    "        ),\n",
    "        name=\"legal\",\n",
    "    )\n",
    "\n",
    "    # Define custom aggregator callback that uses the chat client to summarize\n",
    "    async def summarize_results(results: list[Any]) -> str:\n",
    "        \"\"\"Custom aggregator that synthesizes expert outputs using an LLM.\"\"\"\n",
    "        # Extract one final assistant message per agent\n",
    "        expert_sections: list[str] = []\n",
    "        for r in results:\n",
    "            try:\n",
    "                messages = getattr(r.agent_run_response, \"messages\", [])\n",
    "                final_text = messages[-1].text if messages and hasattr(messages[-1], \"text\") else \"(no content)\"\n",
    "                expert_sections.append(f\"{getattr(r, 'executor_id', 'expert')}:\\n{final_text}\")\n",
    "            except Exception as e:\n",
    "                expert_sections.append(f\"{getattr(r, 'executor_id', 'expert')}: (error: {type(e).__name__}: {e})\")\n",
    "\n",
    "        # Ask the model to synthesize a concise summary of the experts' outputs\n",
    "        system_msg = ChatMessage(\n",
    "            Role.SYSTEM,\n",
    "            text=(\n",
    "                \"You are a helpful assistant that consolidates multiple domain expert outputs \"\n",
    "                \"into one cohesive, concise summary with clear takeaways. Keep it under 200 words.\"\n",
    "            ),\n",
    "        )\n",
    "        user_msg = ChatMessage(Role.USER, text=\"\\n\\n\".join(expert_sections))\n",
    "\n",
    "        response = await chat_client.get_response([system_msg, user_msg])\n",
    "        # Return the model's final assistant text as the completion result\n",
    "        return response.messages[-1].text if response.messages else \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cdb521",
   "metadata": {},
   "source": [
    "## Build Workflow with Custom Aggregator\n",
    "\n",
    "### Key Method:\n",
    "- **`.with_aggregator(callback)`**: Replaces default aggregator\n",
    "- Callback signature: `async def(list[AgentExecutorResponse]) -> Any`\n",
    "- Can be sync or async function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36edf37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Build with custom aggregator callback\n",
    "    workflow = (\n",
    "        ConcurrentBuilder()\n",
    "        .participants([researcher, marketer, legal])\n",
    "        .with_aggregator(summarize_results)\n",
    "        .build()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd552e4",
   "metadata": {},
   "source": [
    "## Execute and Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a589a43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    events = await workflow.run(\"We are launching a new budget-friendly electric bike for urban commuters.\")\n",
    "    outputs = events.get_outputs()\n",
    "\n",
    "    if outputs:\n",
    "        print(\"===== Final Consolidated Output =====\")\n",
    "        print(outputs[0])  # Get the first (and typically only) output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbf2300",
   "metadata": {},
   "source": [
    "## Run the Complete Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8930ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "await run_concurrent_with_custom_aggregator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0568c305",
   "metadata": {},
   "source": [
    "## Expected Output\n",
    "\n",
    "```\n",
    "===== Final Consolidated Output =====\n",
    "Urban e-bike demand is rising rapidly due to eco-awareness, urban congestion, and high fuel costs,\n",
    "with market growth projected at a ~10% CAGR through 2030. Key customer concerns are affordability,\n",
    "easy maintenance, convenient charging, compact design, and theft protection. Differentiation opportunities\n",
    "include integrating smart features (GPS, app connectivity), offering subscription or leasing options, and\n",
    "developing portable, space-saving designs. Partnering with local governments and bike shops can boost visibility.\n",
    "\n",
    "Risks include price wars eroding margins, regulatory hurdles, battery quality concerns, and heightened expectations\n",
    "for after-sales support. Accurate, substantiated product claims and transparent marketing (with range disclaimers)\n",
    "are essential. All e-bikes must comply with local and federal regulations on speed, wattage, safety certification,\n",
    "and labeling. Clear warranty, safety instructions (especially regarding batteries), and inclusive, accessible\n",
    "marketing are required. For connected features, data privacy policies and user consents are mandatory.\n",
    "\n",
    "Effective messaging should target young professionals, students, eco-conscious commuters, and first-time buyers,\n",
    "emphasizing affordability, convenience, and sustainability. Slogan suggestion: \"Charge Ahead—City Commutes Made\n",
    "Affordable.\" Legal review in each target market, compliance vetting, and robust customer support policies are\n",
    "critical before launch.\n",
    "```\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "### 1. Custom Aggregator Benefits\n",
    "- **Synthesis**: Consolidate multiple perspectives into unified output\n",
    "- **Filtering**: Select best response or combine intelligently\n",
    "- **Scoring**: Rank or evaluate agent outputs\n",
    "- **Formatting**: Transform to specific output structure\n",
    "\n",
    "### 2. Aggregator Callback Signature\n",
    "```python\n",
    "async def custom_aggregator(results: list[AgentExecutorResponse]) -> Any:\n",
    "    # results: List of responses from all participants\n",
    "    # Return: Any type (string, dict, custom object)\n",
    "    pass\n",
    "```\n",
    "\n",
    "### 3. Accessing Agent Responses\n",
    "Each `AgentExecutorResponse` contains:\n",
    "- `executor_id`: Identifier of the agent\n",
    "- `agent_run_response`: The AgentRunResponse with messages\n",
    "- `full_conversation`: Complete conversation history\n",
    "\n",
    "### 4. LLM-Based Aggregation Pattern\n",
    "1. Extract content from all agent responses\n",
    "2. Format as structured input for summarizer\n",
    "3. Use LLM to consolidate/synthesize\n",
    "4. Return processed result\n",
    "\n",
    "### 5. Other Custom Aggregator Examples\n",
    "\n",
    "#### Best Response Selection:\n",
    "```python\n",
    "async def select_best(results: list[Any]) -> str:\n",
    "    # Use LLM to evaluate and select best response\n",
    "    evaluations = []\n",
    "    for r in results:\n",
    "        score = await evaluate_quality(r)\n",
    "        evaluations.append((score, r))\n",
    "    return max(evaluations, key=lambda x: x[0])[1]\n",
    "```\n",
    "\n",
    "#### Structured Output:\n",
    "```python\n",
    "async def create_report(results: list[Any]) -> dict:\n",
    "    return {\n",
    "        \"research\": extract_research(results[0]),\n",
    "        \"marketing\": extract_marketing(results[1]),\n",
    "        \"legal\": extract_legal(results[2]),\n",
    "        \"summary\": await synthesize(results)\n",
    "    }\n",
    "```\n",
    "\n",
    "#### Consensus Building:\n",
    "```python\n",
    "async def build_consensus(results: list[Any]) -> str:\n",
    "    # Extract common themes across all responses\n",
    "    # Identify disagreements\n",
    "    # Use LLM to synthesize consensus view\n",
    "    pass\n",
    "```\n",
    "\n",
    "### 6. Sync vs. Async Aggregators\n",
    "- **Async**: Required if calling APIs (e.g., LLM synthesis)\n",
    "- **Sync**: Fine for simple transformations or filtering\n",
    "\n",
    "### 7. Error Handling\n",
    "- Always handle cases where agent responses may be incomplete\n",
    "- Use try-except when extracting from responses\n",
    "- Provide fallback values for missing data\n",
    "\n",
    "### 8. Production Considerations\n",
    "- Monitor aggregation LLM costs (additional API call)\n",
    "- Add timeout handling for aggregator logic\n",
    "- Cache aggregation results if repeatable\n",
    "- Log input and output of aggregator for debugging\n",
    "- Consider fallback to default aggregator on errors"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}